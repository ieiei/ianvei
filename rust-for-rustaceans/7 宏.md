本质上，宏是让编译器为您编写代码的工具。您为编译器提供一个公式，用于在给定一些输入参数的情况下生成代码，编译器会将宏的每次调用替换为运行该公式的结果。您可以将宏视为自动代码替换，您可以在其中定义替换规则。

Rust 的宏有许多不同的形状和大小，可以轻松实现许多不同形式的代码生成。两种主要类型是“声明性”宏和“过程性”宏，我们将在本章中探讨这两种类型。我们还将研究宏在日常编码中派上用场的一些方法，以及更高级的使用中出现的一些陷阱。

来自基于 C 语言的程序员可能已经习惯了 C 和 C++ 的邪恶之地，您可以使用 #define 将每个 true 更改为 false，或者删除所有出现的 else 关键字。如果你是这种情况，你需要将宏与做“坏事”的感觉分开。 Rust 中的宏与 C 宏的狂野西部相去甚远。它们（大部分）遵循明确定义的规则，并且相当防误用。

## 声明式宏

声明式宏是使用 Macro_rules 定义的宏！语法，它使您可以方便地定义类似函数的宏，而无需为此目的编写专用的包（就像处理过程宏一样）。定义声明性宏后，您可以使用宏名称后跟感叹号来调用它。我喜欢将这种宏视为一种编译器辅助的搜索和替换：它可以完成许多常规的、结构良好的转换任务，并消除重复的样板文件。根据到目前为止您使用 Rust 的经验，您识别为宏的大多数宏可能都是声明性宏。但请注意，并非所有类似函数的宏都是声明性宏；宏规则！ format_args 本身就是一个例子！是另一个。这 ！后缀仅向编译器指示宏调用将在编译时替换为不同的源代码。

**N O T E**  *Since Rust’s parser specifically recognizes and parses macro invocations annotated with* *!**, you can use them only in places where the parser allows them. They work in most places you’d expect, like in expression position or in an* *impl* *block, but not everywhere. For example, you cannot (at the time of writing) invoke a function-like macro where an identifier or match arm is expected.* 

为什么声明性宏被称为声明性宏可能不是很明显。毕竟，您不是“声明”了程序中的所有内容吗？在这种情况下，*声明性*指的是这样一个事实：您不说*如何*将宏的输入转换为输出，只是您希望当输入是 B 时输出看起来像 A。您声明它应该如此，编译器会计算出使您的声明成为现实所必须发生的所有解析重新连接。这使得声明性宏变得简洁和富有表现力，尽管它也有使它们变得相当神秘的趋势，因为你用来表达声明的语言有限。

### *When to Use Them*

当您发现自己一遍又一遍地编写相同的代码并且您不想这样做时，声明性宏主要有用。它们最适合相当机械的替换 - 如果您的目标是进行奇特的代码转换或大量代码生成，那么过程宏可能更适合。

当我发现自己编写重复且结构相似的代码时（例如在测试和特征实现中），我最常使用声明性宏。对于测试，我经常想多次运行相同的测试，但配置略有不同。我可能有如清单 7-1 所示的内容。

``` rust
fn test_inner<T>(init: T, frobnify: bool) { ... }
#[test]
fn test_1u8_frobnified() {
  test_inner(1u8, true);
}
// ... 
#[test]
fn test_1i128_not_frobnified() {
  test_inner(1i128, false);
}
```
Listing 7-1: Repetitive testing code 

虽然这种方法可行，但它太冗长、太重复，而且太容易出现手动错误。使用宏我们可以做得更好，如清单 7-2 所示。

``` rust
macro_rules! test_battery {
  ($($t:ty as $name:ident),*)) => {
		$(
 			mod $name { 
        #[test]
        fn frobnified() { test_inner::<$t>(1, true) }
        #[test]
        fn unfrobnified() { test_inner::<$t>(1, false) }
			} 
		)* 
	} 
} 

test_battery! {
  u8 as u8_tests,
  // ...
  i128 as i128_tests
); 
```
*Listing 7-2: Making a macro repeat for you*

该宏将每个逗号分隔的指令扩展为自己的模块，然后包含两个测试，一个用 true 调用 test_inner，另一个用 false 调用 test_inner。虽然宏定义并不简单，但它使得添加更多测试变得更加容易。每种类型都是 test_battery 中的一行！调用，宏将负责生成 true 和 false 参数的测试。我们还可以让它为 init 的不同值生成测试。我们现在已经大大降低了忘记测试特定配置的可能性！

特征实现的故事是类似的。如果您定义自己的特征，您通常会希望为标准库中的许多类型实现该特征，即使这些实现很简单。假设您发明了 Clone 特征，并希望为标准库中的所有 Copy 类型实现它。您可以使用清单 7-3 中的宏，而不是为每个宏手动编写实现。

``` rust
macro_rules! clone_from_copy {
  ($($t:ty),*) => {
    $(impl Clone for $t {
      fn clone(&self) -> Self { *self }
		})* 
	} 
}
clone_from_copy![bool, f32, f64, u8, i8, /* ... */];
```

*Listing 7-3: Using a macro to implement a trait for many similar types in one fell swoop*

在这里，我们为每个提供的类型生成一个 Clone 实现，其主体仅使用 * 来复制 &self。您可能想知道为什么我们不添加 Clone for T where T: Copy 的全面实现。我们可以这样做，但不这样做的一个重要原因是，它会强制其他板条箱中的类型也对它们自己恰好是 Copy 的类型使用相同的 Clone 实现。一个名为“专业化”的实验性编译器功能可以提供一种解决方法，但在撰写本文时，该功能的稳定性仍有一段路要走。因此，目前我们最好专门枚举类型。这种模式还扩展到简单的转发实现之外：例如，您可以轻松地更改清单 7-3 中的代码来为所有整数类型实现 AddOne 特征！

**N O T E** *如果您发现自己想知道是否应该使用泛型或声明性宏，那么您应该使用泛型。泛型通常比宏更符合人体工程学，并且与语言中的其他结构集成得更好。考虑这个经验法则：如果您的代码根据类型而更改，请使用泛型；否则，使用宏。*

### *它们如何工作

每种编程语言都有一个“语法”，它规定了如何将构成源代码的各个字符转换为“标记”。 标记是语言的最低级构建块，例如数字、标点符号、字符串和字符文字以及标识符； 在这个级别上，语言关键字和变量名之间没有区别。 例如，文本 (value + 4) 将由类 Rust 语法中的 Fivetoken 序列 (, value, +, 4, ) 表示。 将文本转换为标记的过程还在编译器的其余部分和解析文本的粗糙低级细节之间提供了一个抽象层。 例如，在标记表示中，没有空格的概念，并且 /*"foo"*/ 和 "/*foo*/" 具有不同的表示形式（前者没有标记，后者是带有 内容/*foo*/)。

一旦源代码被转换为标记序列，编译器就会遍历该序列并为标记分配语法含义。 例如，() 分隔的标记组成一个组，! 标记表示宏调用，等等。 这就是*解析*的过程，最终产生一个描述源代码所表示的结构的抽象语法树（AST）。 例如，考虑表达式 let x = || 4，它由标记序列let（关键字）、x（标识符）、=（标点符号）、| 的两个实例组成。 （标点符号）和 4（字面意思）。 当编译器将其转换为语法树时，它将其表示为一个*语句*，其*模式*是*标识符* x，其右侧*表达式*是一个*闭包*，它有一个空*参数列表*并且 *整数文字* 4 的*文字表达式* 作为其主体。 请注意语法树表示如何比标记序列丰富得多，因为它按照语言语法为标记组合分配语法含义。

Rust 宏规定了给定的标记序列转变为的语法树——当编译器在解析过程中遇到宏调用时，它必须评估宏以确定替换标记，这最终将成为宏调用的语法树。 然而，此时编译器仍在解析标记，并且可能还无法评估宏，因为它所做的只是解析宏定义的标记。 相反，编译器会推迟对宏调用分隔符中包含的任何内容的解析，并记住输入标记序列。 当编译器准备好评估指示的宏时，它会通过标记序列评估宏，解析它生成的标记，并将生成的语法树替换到宏调用所在的树中。

从技术上讲，编译器确实对宏的输入进行了一些解析。 具体来说，它解析出字符串文字和分隔组等基本内容，从而生成一系列标记*树*而不仅仅是标记。 例如，代码 x - (a.b + 4) 解析为三个令牌树的序列。 第一个标记树是单个标记，即标识符 x，第二个是单个标记，即标点符号 -，第三个是一组（使用括号作为分隔符），它本身由五个标记组成的序列 树：a（标识符），. （标点符号）、b（另一个标识符）、+（另一个标点符号）和 4（文字）。 这意味着宏的输入不一定是有效的 Rust，但它必须包含 Rust 编译器可以解析的代码。 例如，在 Rust 中，您不能在宏调用之外编写 for <- x，但可以在宏调用内部编写，只要宏生成有效的语法即可。 另一方面，您不能将 for { 传递给宏，因为它没有右大括号。

声明性宏始终生成有效的 Rust 作为输出。 您不能让宏生成，例如，函数调用的前半部分或 if 没有后面的块。 声明性宏必须生成一个表达式（基本上是可以分配给变量的任何内容）、一条语句（例如 let x = 1;）、一个项目（例如特征定义或 impl 块）、类型或匹配模式。 这使得 Rust 宏不易被滥用：您根本无法编写生成无效 Rust 代码的声明性宏，因为宏定义本身无法编译！

这实际上就是高层声明性宏的全部内容——当编译器遇到宏调用时，它将调用分隔符中包含的标记传递给宏，解析生成的标记流，并用生成的 AST 替换宏调用。

### *如何编写声明式宏*

对声明性宏支持的所有语法的详尽解释超出了本书的范围。 然而，我们将介绍基础知识，因为有一些奇怪的地方值得指出。

声明性宏由两个主要部分组成：*匹配器*和*转录器*。 给定的宏可以有许多匹配器，每个匹配器都有一个关联的转录器。 当编译器找到宏调用时，它会从第一个到最后一个遍历宏的匹配器，当它找到与调用中的标记匹配的匹配器时，它会通过遍历相应转录器的标记来替换该调用。 清单 7-4 显示了声明性宏规则的不同部分如何组合在一起。

```
macro_rules! /* macro name */ {
  (/* 1st matcher */) => { /* 1st transcriber */ };
  (/* 2nd matcher */) => { /* 2nd transcriber */ };
} 
```

*Listing 7-4: Declarative macro definition components*

**Matchers**

您可以将宏匹配器视为一棵令牌树，编译器尝试以预定义的方式扭曲和弯曲它，以匹配在调用站点给出的输入令牌树。 例如，考虑一个带有匹配器 $a:ident + $b:expr 的宏。 该匹配器将匹配任何标识符 (:ident)，后跟一个加号，后跟任何 Rust 表达式 (:expr)。 如果使用 x + 3 * 5 调用宏，编译器会注意到匹配器在设置 $a = x 和 $b = 3 * 5 时匹配。即使 * 从未出现在匹配器中，编译器也会意识到 3 * 5 是一个有效的表达式，因此它可以与 $b:expr 匹配，$b:expr 接受任何表达式（:expr 部分）。

匹配器可能会变得非常复杂，但它们具有巨大的表达能力，就像正则表达式一样。 对于一个不太复杂的示例，此匹配器接受一个或多个以 key => value 格式给出的 (+) 逗号分隔 (),) 键/值对的序列 ($())：

``` rust
$($key:expr => $value:expr),+
```

而且，至关重要的是，使用此匹配器调用宏的代码可以为键或值提供任意复杂的表达式 - 匹配器的魔力将确保键和值表达式被适当地分区。

宏规则支持多种*片段类型*； 您已经见过用于标识符的 :ident 和用于表达式的 :expr，但还有用于类型的 :ty 甚至用于任何单个标记树的 :tt！ 您可以在 Rust 语言参考 (*https://doc.rust-lang .org/reference/macros-by-example.html*) 的第 3 章中找到片段类型的完整列表。 这些加上重复匹配模式的机制 ($())，使您能够匹配最简单的代码模式。 但是，如果您发现很难用匹配器表达您想要的模式，您可能想尝试使用过程宏，在这种情况下您不需要遵循 Macro_rules! 的严格语法！ 需要。 我们将在本章后面更详细地讨论这些内容。

**Transcribers** 

Once the compiler has matched a declarative macro matcher, it generates code using the matcher’s associated transcriber. The variables defined by a macro matcher are called *metavariables*, and the compiler substitutes any occurrence of each metavariable in the transcriber (like \$(),+ in that same example), you can use the same syntax in the transcriber and it will be repeated once for each match in the input, with each expansion holding the appropriate substitution for each metavariable for that iteration. For example, for the $key and $value matcher, we could write the following transcriber to generate an insert call into some map for each $key/$value pair that was matched: 

``` rust
$(map.insert($key, $value);)+
```

Notice that here we want a semicolon for each repetition, not just to delimit the repetition, so we place the semicolon inside the repetition parentheses. 

**N O T E** *You must use a metavariable in each repetition in the transcriber so that the compiler knows which repetition in the matcher to use (in case there is more than one).* 

**Hygiene** 

You may have heard that Rust macros are *hygienic*, and perhaps that being hygienic makes them safer or nicer to work with, without necessarily understanding what that means. When we say Rust macros are hygienic, we mean that a declarative macro (generally) cannot affect variables that aren’t explicitly passed to it. A trivial example is that if you declare a variable with the name foo, and then call a macro that also defines a variable named foo, the macro’s foo is by default not visible at the call site (the place where the macro is called from). Similarly, macros cannot access variables defined at the call site (even self) unless they are explicitly passed in. You can, most of the time, think of macro identifiers as existing in their own namespace that is separate from that of the code they expand into. For an example, take a look at the code in Listing 7-5, which has a macro that tries (and fails) to shadow a variable at the call site. 

``` rust
macro_rules! let_foo {
  ($x:expr) => {
let foo = $x; } 
}
let foo = 1;
// expands to let foo = 2;
let_foo!(2);
assert_eq!(foo, 1);
```

*Listing 7-5: Macros exist in their own little universes. Mostly.*

After the compiler expands let_foo!(2), the assert looks like it should fail. However, the foo from the original code and the one generated by the macro exist in different universes and have no relationship to one another beyond that they happen to share a human-readable name. In fact, the compiler will complain that the let foo in the macro is an unused variable. This hygiene is very helpful in making macros easier to debug—you don’t have to worry about accidentally shadowing or overwriting variables in the macro caller just because you happened to choose the same variable names! 

This hygienic separation does not apply beyond variable identifiers, however. Declarative macros do share a namespace for types, modules, and functions with the call site. This means your macro can define new functions that can be called in the invoking scope, add new implementations to a type defined elsewhere (and not passed in), introduce a new module that can then be accessed where the macro was invoked, and so on. This is by design—if macros could not affect the broader code like this, it would be much more cumbersome to use them to generate types, trait implementations, and functions, which is where they come in most handy. 

The lack of hygiene for types in macros is particularly important when writing a macro you want to export from your crate. For the macro to truly be reusable, you cannot assume anything about what types will be in scope at the caller. Maybe the code that calls your macro has a mod std {} defined or has imported its own Result type. To be on the safe side, make sure you use fully specified types like ::core::option::Option or ::alloc::boxed::Box. If you specifically need to refer to something in the crate that defines the macro, use the special metavariable $crate. 

**NOTE** *Avoid using* *::std* *paths if you can so that the macro will continue to work in* *no_std* *crates.* 

You can choose to share identifiers between a macro and its caller if you want the macro to affect a specific variable in the caller’s scope. The key is to remember where the identifier originated, because that’s the namespace the identifier will be tied to. If you put let foo = 1; in a macro, the identifier foo originates in the macro and will never be available to the identifier namespace at the caller. If, on the other hand, the macro takes $foo:ident as an argument and then writes let $foo = 1;, when the caller invokes the macro with !(foo), the identifier will have originated in the caller and will therefore refer to foo in the caller’s scope. 

The identifier does not have to be quite so explicitly passed, either; any identifier that appears in code that originates outside the macro will refer to the identifier in the caller’s scope. In the example in Listing 7-6, the variable identifier appears in an :expr but nonetheless has access to the variable in the caller’s scope. 

``` rust
macro_rules! please_set {
	($i:ident, $x:expr) => {
		$i = $x; 
	} 
}
let mut x = 1;
please_set!(x, x + 1);
assert_eq!(x, 2);
```

*Listing 7-6: Giving macros access to identifiers at the call site*

We could have used = $i + 1 in the macro instead, but we could not have used = x + 1 as the name x is not available in the macro’s definition scope. 

One last note on declarative macros and scoping: unlike pretty much everything else in Rust, declarative macros exist in the source code only after they are declared. If you try to use a macro that you define further down in the file, this will not work! This applies globally to your project; if you declare a macro in one module and want to use it in another, the module you declare the macro in must appear earlier in the crate, not later. If foo and bar are mod- ules at the root of a crate, and foo declares a macro that bar wants to use, then mod foo must appear before mod bar in *lib.rs*! 

**NOTE** *There is one exception to this odd scoping of macros (formally called* textual scoping*), and that is if you mark the macro with* *#[macro_export]**. That annotation effectively hoists the macro to the root of the crate and marks it as* *pub* *so that it can then be used anywhere in your crate or by your crate’s dependents.* 

## 过程宏

You can think of a procedural macro as a combination of a parser and code generation, where you write the glue code in between. At a high level, with procedural macros, the compiler gathers the sequence of input tokens to the macro and runs your program to figure out what tokens to replace them with. 

Procedural macros are so called because you define *how* to generate code given some input tokens rather than just writing what code gets gener- ated. There are very few smarts involved on the compiler’s side—as far as it is aware, the procedural macro is more or less a source code preprocessor that may replace code arbitrarily. The requirement that your input can be parsed as a stream of Rust tokens still holds, but that’s about it! 

### *Types of Procedural Macros*

Procedural macros come in three different flavors, each specialized to a particular common use case: 

- Function-like macros, like the ones that macro_rules! generates 
- Attribute macros, like #[test] 
- Derive macros, like #[derive(Serialize)] 

  All three types use the same underlying mechanism: the compiler provides your macro with a sequence of tokens, and it expects you to produce a sequence of tokens in return that are (probably) related to the input tree. However, they differ in how the macro is invoked and how its output is handled. We’ll cover each one briefly. 

**Function-Like Macros** 

The function-like macro is the simplest form of procedural macro. Like a declarative macro, it simply replaces the macro code at the call site with the code that the procedural macro returns. However, unlike with declarative macros, all the guard rails are off: these macros (like all procedural macros) are not required to be hygienic and will not protect you from interacting with identifiers in the surrounding code at the call site. Instead, your macros are expected to explicitly call out which identifiers should overlap with the surrounding code (using Span::call_site) and which should be treated as private to the macro (using Span::mixed_site, which we’ll discuss later). 

**Attribute Macros** 

The attribute macro also replaces the item that the attribute is assigned to wholesale, but this one takes two inputs: the token tree that appears in the attribute (minus the attribute’s name) and the token tree of the entire item it is attached to, including any other attributes that item may have. Attribute macros allow you to easily write a procedural macro that transforms an item, such as by adding a prelude or epilogue to a function definition (like #[test] does) or by modifying the fields of a struct. 

**Derive Macros** 

The derive macro is slightly different from the other two in that it adds to, rather than replaces, the target of the macro. Even though this limita- tion may seem severe, derive macros were one of the original motivating factors behind the creation of procedural macros. Specifically, the serde crate needed derive macros to be able to implement its now-well-known #[derive(Serialize, Deserialize)] magic. 

Derive macros are arguably the simplest of the procedural macros, since they have such a rigid form: you can append items only after the annotated item; you can’t replace the annotated item, and you cannot have the derivation take arguments. Derive macros do allow you to define *helper attributes*—attributes that can be placed inside the annotated type to give clues to the derive macro (like #[serde(skip)])—but these function mostly like markers and are not independent macros. 

### *The Cost of Procedural Macros*

Before we talk about when each of the different procedural macro types is appropriate, it’s worth discussing why you may want to think twice before you reach for a procedural macro—namely, increased compile time. 

Procedural macros can significantly increase compile times for two main reasons. The first is that they tend to bring with them some pretty heavy dependencies. For example, the syn crate, which provides a parser for Rust token streams that makes the experience of writing procedural macros much easier, can take tens of seconds to compile with all features enabled. You can (and should) mitigate this by disabling features you do not need and compiling your procedural macros in debug mode rather than release mode. Code often compiles several times faster in debug mode, and for most procedural macros, you won’t even notice the difference in execution time. 

The second reason why procedural macros increase compile time is that they make it easy for you to generate a lot of code without realizing it. While the macro saves you from having to actually type the generated code, it does not save the compiler from having to parse, compile, and optimize it. As you use more procedural macros, that generated boilerplate adds up, and it can bloat your compile times. 

That said, the actual execution time of procedural macros is rarely a factor in overall compile time. While the compiler has to wait for the procedural macro to do its thing before it can continue, in practice, most procedural macros don’t do any heavy computation. That said, if your procedural macro is particularly involved, you may end up with your compiles spending a significant chunk of execution time on your procedural macro code, which is worth keeping an eye out for! 

### *So You Think You Want a Macro*

Let’s now look at some good uses for each type of procedural macro. We’ll start with the easy one: derive macros. 

**When to Use Derive Macros** 

Derive macros are used for one thing, and one thing only: to automate the implementation of a trait where automation is possible. Not all traits have obvious automated implementations, but many do. In practice, you should consider adding a derive macro for a trait only if the trait is implemented often and if its implementation for any given type is fairly obvious. The first of these conditions may seem like common sense; if your trait is going to be implemented only once or twice, it’s probably not worth writing and maintaining a convoluted derive macro for it. 

The second condition may seem stranger, however: what does it mean for the implementation to be “obvious”? Consider a trait like Debug. If you were told what Debug does and were shown a type, you would probably expect an implementation of Debug to output the name of each field along- side the debug representation of its value. And that’s what derive(Debug) does. What about Clone? You’d probably expect it to just clone every field— and again, that’s what derive(Clone) does. With derive(serde::Serialize), we expect it to serialize every field and its value, and it does just that. In general, you want the derivation of a trait to match the developer’s intuition for what it probably does. If there is no obvious derivation for a trait, or worse yet, if your derivation does not match the obvious implementation, then you’re probably better off not giving it a derive macro. 


**When to Use Function-Like Macros** 

Function-like macros are harder to give a general rule of thumb for. You might say you should use function-like macros when you want a function-like macro but can’t express it with macro_rules!, but that’s a fairly subjective guideline. You can do a lot with declarative macros if you really put your mind to it, after all! 

There are two particularly good reasons to reach for a function-like macro: 

- If you already have a declarative macro, and its definition is becoming so hairy that the macro is hard to maintain. 
- If you have a pure function that you need to be able to execute at compile time but cannot express it with const fn. An example of this is the phf crate, which generates a hash map or set using a perfect hash function when given a set of keys provided at compile time. Another is hex-literal, which takes a string of hexadecimal characters and replaces it with the corresponding bytes. In general, anything that does not merely trans- form the input at compile time but actually computes over it is likely to be a good candidate. 

I do not recommend reaching for a function-like macro just so that you can break hygiene within your macro. Hygiene for function-like macros is a feature that avoids many debugging headaches, and you should think very carefully before you intentionally break it. 

**When to Use Attribute Macros** 

That leaves us with attribute macros. Though these are arguably the most general of procedural macros, they are also the hardest to know when to use. Over the years and time and time again, I have seen four ways in which attribute macros add tremendous value. 

**Test generation** 

​	It is very common to want to run the same test under multiple different configurations, or many similar tests with the same bootstrapping code. While a declarative macro may let you express this, your code is often easier to read and maintain if you have an attribute like #[foo_test] that introduces a setup prelude and postscript in each annotated test, or a repeatable attribute like #[test_case(1)] #[test_case(2)] to mark that a given test should be repeated multiple times, once with each input. 

**Framework annotations** 

​	Libraries like rocket use attribute macros to augment functions and types with additional information that the framework then uses without the user having to do a lot of manual configuration. It’s so much more convenient to be able to write #[get("/<name>")] fn hello(name: String) than to have to set up a configuration struct with function pointers and the like. Essentially, the attributes make up a miniature domain-specific language (DSL) that hides a lot of boilerplate that’d otherwise be necessary. Similarly, the asynchronous I/O framework tokio lets you use #[tokio::main] async fn main() to automatically set up a runtime and run your asynchronous code, thereby saving you from writing the same runtime setup in every asynchronous application’s main function. 

**Transparent middleware** 

​	Some libraries want to inject themselves into your application in unobtrusive ways to provide added value that does not change the application’s functionality. For example, tracing and logging libraries like tracing and metric collection libraries like metered allow you to transparently instrument a function by adding an attribute to it, and then every call to that function will run some additional code dictated by the library. 

**Type transformers** 

​	Sometimes you want to go beyond merely deriving traits for a type and actually change the type’s definition in some fundamental way. In these cases, attribute macros are the way to go. The pin_project crate is a great example of this: its primary purpose is not to implement a particular trait but rather to ensure that all pinned access to fields of a given type happens according to the strict rules that are set forth by Rust’s Pin type and the Unpin trait (we’ll talk more about those types in Chapter 8). It does this by generating additional helper types, adding methods to the annotated type, and introducing static safety checks to ensure that users don’t accidentally shoot themselves in the foot. While pin_project could have been implemented with a procedural derive macro, that derived trait implementation would likely not have been obvious, which violates one of our rules for when to use procedural macros. 

### *它们如何工作?*

At the heart of all procedural macros is the TokenStream type, which can be iterated over to get the individual TokenTree items that make up that token stream. A TokenTree is either a single token—like an identifier, punctuation, or a literal—or another TokenStream enclosed in a delimiter like () or {}. By walking a TokenStream, you can parse out whatever syntax you wish as long as the individual tokens are valid Rust tokens. If you want to parse your input specifically as Rust code, you will likely want to use the syn crate, which implements a complete Rust parser and can turn a TokenStream into an easy- to-traverse Rust AST. 

With most procedural macros, you want to not only parse a TokenStream but also produce Rust code to be injected into the program that invokes the procedural macro. There are two main ways to do so. The first is to manually construct a TokenStream and extend it one TokenTree at a time. The second is to use TokenStream’s implementation of FromStr, which lets you parse a string that contains Rust code into a TokenStream with "".parse::<TokenStream>(). You can also mix and match these; if you want to prepend some code to your macro’s input, just construct a TokenStream for the prologue, and then use the Extend trait to append the original input. 

**NOTE** *TokenStream* *also implements* *Display**, which pretty-prints the tokens in the stream. This comes in super handy for debugging!* 

Tokens are very slightly more magical than I’ve described so far in that every token, and indeed every TokenTree, also has a *span*. Spans are how the compiler ties generated code back to the source code that generated it. Every token’s span marks where that token originated. For example, consider a (declarative) macro like the one in Listing 7-7, which generates a trivial Debug implementation for the provided type. 

```rust
macro_rules! name_as_debug {
  ($t:ty) => {
    impl ::core::fmt::Debug for $t {
      fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result
      { ::core::write!(f, ::core::stringify!($t)) }
}};}      
```

*Listing 7-7: A very simple macro for implementing Debug*

Now let’s imagine that someone invokes this macro with name_as_debug! (u31). Technically, the compiler error occurs inside the macro, specifically where we write for $t (the other use of $t can handle an invalid type). But we’d like the compiler to point the user at the u31 in their code—and indeed, that’s what spans let us do. 

The span of the $t in the generated code is the code mapped to $t in the macro invocation. That information is then carried through the compiler and associated with the eventual compiler error. When that compiler error is eventually printed, the compiler will print the error from inside the macro saying that the type u31 does not exist but will highlight the u31 argument in the macro invocation, since that’s the error’s associated span! 

Spans are quite flexible, and they enable you to write procedural macros that can produce sophisticated error messages if you use the compile_error! macro. As its name implies, compile_error! causes the compiler to emit an error wherever it is placed with the provided string as the message. This may not seem very useful, until you pair it with a span. By setting the span of the TokenTree you generate for the compile_error! invocation to be equal to the span of some subset of the input, you are effectively telling the compiler to emit this compiler error and point the user to this part of the source. Together, these two mechanisms let a macro produce errors that seem to stem from the relevant part of the code, even though the actual compiler error is somewhere in the generated code that the user never even sees! 

**NOTE** *If you’ve ever been curious how* *syn**’s error handling works, its* *Error* *type implements an* *Error::to_compile_error* *method, which turns it into a* *TokenStream* *that holds only a* *compile_error!* *directive. What’s particularly neat with* *syn**’s* *Error* *type is that it internally holds a collection of errors, each of which produces a distinct* *compile_error!* *directive with its own span so that you can easily produce multiple independent errors from your procedural macro.* 

The power of spans doesn’t end there; spans are also how Rust’s macro hygiene is implemented. When you construct an Ident token, you also give the span for that identifier, and that span dictates the scope of that identifier. If you set the identifier’s span to be Span::call_site(), the identifier is resolved where the macro was called from and will thus not be isolated from the surrounding scope. If, on the other hand, you set it to Span::mixed _site() then (variable) identifiers are resolved at the macro definition site, and so will be completely hygienic with respect to similarly named variables at the call site. Span::mixed_site is so called because it matches the rules around identifier hygiene for macro_rules!, which, as we discussed earlier, “mixes” identifier resolution between using the macro definition site for variables and using the call site for types, modules, and everything else. 

## Summary

In this chapter we covered both declarative and procedural macros, and looked at when you might find each of them useful in your own code. We also took a deeper dive into the mechanisms that underpin each type of macro and some of the features and gotchas to be aware of when you write your own macros. In the next chapter, we’ll start our journey into asynchronous programming and the Future trait. I promise—it’s just on the next page. 