
顾名思义，异步编程是不同步的编程。 从较高层次来看，异步操作是在后台执行的操作 - 程序不会等待异步操作完成，而是立即继续执行下一行代码。

如果您还不熟悉异步编程，那么该定义可能会觉得不够，因为它实际上并没有解释什么是异步编程。 要真正理解异步编程模型及其在 Rust 中的工作原理，我们必须首先深入研究替代方案是什么。 也就是说，我们需要先了解“同步”编程模型，然后才能了解“异步”编程模型。 这对于澄清概念和演示使用异步编程的权衡都很重要：异步解决方案并不总是正确的！ 本章开始时，我们将首先快速浏览一下异步编程作为概念的动机； 然后我们将深入了解 Rust 中的异步实际上是如何工作的。
## What’s the Deal with Asynchrony?

在详细了解同步和异步编程模型之前，我们首先需要快速了解一下计算机在运行程序时实际上在做什么。

计算机速度很快。 真的很快。 事实上，速度如此之快，以至于他们大部分时间都在等待事情发生。 除非您正在解压缩文件、编码音频或处理数字，否则您的 CPU 很可能大部分时间处于空闲状态，等待操作完成。 它正在等待网络数据包到达、等待鼠标移动、等待磁盘完成一些字节的写入，甚至可能只是等待从主内存的读取完成。 从 CPU 的角度来看，大多数此类事件之间都经过了亿万年。 当这种情况确实发生时，CPU 会再运行一些指令，然后再次返回等待状态。 看看你的 CPU 利用率——它可能处于较低的个位数，而且大部分时间都徘徊在这个位置。

### *Synchronous Interfaces*

同步接口允许您的程序（或者更确切地说，程序中的单个线程）一次仅执行一个操作； 每个操作都必须等待前一个同步操作完成才能运行。 您在野外看到的大多数接口都是同步的：您调用它们，它们会执行一些操作，最终在操作完成时返回，并且您的程序可以从那里继续。 正如我们将在本章后面看到的，其原因是使操作异步需要相当多的额外机制。 除非您需要异步的好处，否则坚持同步模型需要的排场和环境要少得多。

同步接口隐藏了所有这些等待； 应用程序调用一个函数，该函数表示“将这些字节写入此文件”，一段时间后，该函数完成并执行下一行代码。 在幕后，真正发生的事情是操作系统将磁盘写入操作排队，然后让应用程序进入睡眠状态，直到磁盘报告它已完成写入。 应用程序将此视为需要很长时间才能执行的函数，但实际上它根本没有真正执行，只是在等待。

以这种方式顺序执行操作的接口通常也称为*阻塞*，因为接口中的操作必须等待某些外部事件发生才能取得进展*阻塞*进一步执行，直到该事件发生 发生。 无论您将接口称为同步接口还是阻塞接口，其基本思想都是相同的：在当前操作完成之前，应用程序不会继续前进。 当操作等待时，应用程序也在等待。

同步接口通常被认为易于使用且易于推理，因为您的代码一次只执行一行。 但它们也允许应用程序一次只做一件事。 这意味着，如果您希望程序等待用户输入或网络数据包，那么除非您的操作系统专门为此提供了操作，否则您就不走运了。 同样，即使您的应用程序可以在磁盘写入文件时执行一些其他有用的工作，它也没有该选项，因为文件写入操作会阻止执行！

### *Multithreading*

到目前为止，允许并发执行的最常见解决方案是使用*多线程*。 在多线程程序中，每个线程负责执行特定的独立的阻塞操作序列，并且操作系统在线程之间进行复用，以便如果任何线程可以取得进展，则取得进展。 如果一个线程阻塞，其他一些线程可能仍然可以运行，因此应用程序可以继续执行有用的工作。

通常，这些线程使用锁或通道等同步原语相互通信，以便应用程序仍然可以协调它们的工作。 例如，您可能有一个线程等待用户输入，一个线程等待网络数据包，另一个线程等待这些线程中的任何一个在所有三个线程之间共享的通道上发送消息。

多线程为您提供“并发性”——能够同时执行多个独立操作。 由运行应用程序的系统（在本例中为操作系统）来选择未阻塞的线程并决定下一步执行哪个。 如果一个线程被阻塞，它可以选择运行另一个可以取得进展的线程。

多线程与阻塞接口相结合可以让您走得更远，并且大量的生产就绪软件都是以这种方式构建的。 但这种方法并非没有缺点。 首先，跟踪所有这些线程很快就会变得很麻烦； 如果您必须为每个并发任务（包括等待键盘输入等简单任务）启动一个线程，那么线程会快速增加，并且跟踪所有这些线程如何交互、通信和协调所需的额外复杂性也会增加。

其次，线程越多，线程之间的切换成本就越高。 每当一个线程停止运行并且另一个线程重新启动时，您都需要与操作系统调度程序进行一次往返，而这并不是免费的。 在某些平台上，生成新线程也是一个相当重量级的过程。 具有高性能需求的应用程序通常通过重用线程和使用允许您阻止许多相关操作的操作系统调用来减轻这种成本，但最终您会遇到同样的问题：阻塞接口要求您拥有与接口数量一样多的线程。 阻止您想要拨打的电话。

最后，线程将“并行性”引入到您的程序中。 并发和并行之间的区别很微妙，但很重要：并发意味着任务的执行是交错的，而并行意味着多个任务同时执行。 如果您有两个任务，则它们以 ASCII 表示的执行可能看起来像 __-_-（并发）与 \=\=\=\=\=（并行）。 多线程并不一定意味着并行性——即使您有许多线程，但可能只有一个核心，因此在给定时间只有一个线程正在执行——但这两者通常是齐头并进的。 您可以使用互斥体或其他同步原语使两个线程在执行过程中互斥，但这会带来额外的复杂性 - 线程需要并行运行。 虽然并行性通常是一件好事（谁不希望自己的程序在更多内核上运行得更快），但这也意味着您的程序必须处理对共享数据结构的真正同时访问。 这意味着从 Rc、Cell 和 RefCell 转向功能更强大但速度更慢的 Arc 和 Mutex。 虽然您“可能”希望在并发程序中使用后一种类型来启用并行性，但线程“强制”您使用它们。 我们将在第 10 章中更详细地讨论多线程。
### *Asynchronous Interfaces*

现在我们已经探索了同步接口，我们可以看看替代方案：异步或“非阻塞”接口。 异步接口可能不会立即产生结果，而是可能指示结果将在稍后的某个时间可用。 这使调用者有机会同时做其他事情，而不必进入睡眠状态直到特定操作完成。 用 Rust 的话说，异步接口是一种返回 Poll 的方法，如清单 8-1 中所定义。

``` rust
enum Poll<T> {
    Ready(T),
Pending } 
```

*Listing 8-1: The core of asynchrony: the “here you are or come back later” type*

Poll 通常出现在名称以 poll 开头的函数的返回类型中，这些方法表明它们可以尝试执行操作而不会阻塞。 我们将在本章后面介绍他们到底是如何做到这一点的，但一般来说，他们会尝试在正常阻塞之前尽可能多地执行操作，然后返回。 至关重要的是，他们会记住自己停止的地方，以便稍后在再次取得额外进展时可以恢复执行。

这些非阻塞函数使我们能够轻松地同时执行多个任务。 例如，如果您想从网络或用户键盘读取数据（以先有可用事件为准），您所要做的就是循环轮询两者，直到其中一个返回 Poll::Ready。 不需要任何额外的线程或同步！

这里的“循环”这个词应该会让你有点紧张。 您不希望您的程序每秒消耗 30 亿次循环，而距离下一个输入发生可能需要几分钟。 在阻塞接口的世界中，这不是问题，因为操作系统只是将线程置于睡眠状态，然后在发生相关事件时负责将其唤醒，但是在这个勇敢的新环境中等待时，我们如何避免燃烧周期 非阻塞世界？ 这就是本章其余部分将要讨论的内容。

### *Standardized Polling*

为了实现每个库都可以以非阻塞方式使用的世界，我们可以让每个库作者编写自己的轮询方法，所有方法的名称、签名和返回类型都略有不同，但这很快就会变得笨拙。 相反，在 Rust 中，轮询是通过 Future 特征标准化的。 Future 的简化版本如清单 8-2 所示（我们将在本章稍后讨论真正的版本）。

``` rust
trait Future {
    type Output;
    fn poll(&mut self) -> Poll<Self::Output>;
}
```

*Listing 8-2: A simplified view of the *Future* trait*

实现 Future 特征的类型被称为“futures”，代表可能尚不可用的值。 未来可以表示下一次网络数据包进入的时间、下一次鼠标光标移动的时间，或者仅表示经过一段时间的时间点。 您可以将 Future<Output = Foo> 理解为“将来会生成 Foo 的类型”。 像这样的类型在其他语言中通常被称为“承诺”——它们承诺最终会产生指定的类型。 当 future 最终返回 Poll::Ready(T) 时，我们说 future *解析* 为 T。

有了这个特征，我们就可以概括提供 poll 方法的模式。 我们可以使用像recv和keypress这样的方法，而不是像poll_recv和poll_keypress这样的方法，它们都返回具有适当输出类型的impl Future。 这并没有改变你必须轮询它们的事实——我们稍后会处理这个问题——但这确实意味着至少有一个针对这些类型的待处理值的标准化接口，并且我们不需要使用 poll_ 前缀无处不在。

**注意** *一般来说，您不应在 future 返回后再次对其进行轮询* *Poll::Ready**。 如果你这样做了，未来完全有理由感到恐慌。 返回后可以安全轮询的 future* *Ready* *有时被称为* fused *future。*
## Ergonomic Futures

按照我到目前为止所描述的方式编写一个实现 Future 的类型是相当痛苦的。 要了解原因，首先看一下清单 8-3 中相当简单的异步代码块，它只是尝试将消息从输入通道 rx 转发到输出通道 tx。

``` rust
async fn forward<T>(rx: Receiver<T>, tx: Sender<T>) {
	while let Some(t) = rx.next().await {
		tx.send(t).await;
	}
}
```

*Listing 8-3: Implementing a channel-forwarding future using *async* and await* 

该代码使用 async 和 wait 语法编写，看起来与其等效的同步代码非常相似，并且易于阅读。 我们简单地发送循环中收到的每条消息，直到没有更多消息为止，并且每个等待点对应于同步变体可能阻塞的位置。 现在考虑一下您是否必须通过手动实现 Future 特征来表达此代码。 由于每次调用 poll 都从函数的顶部开始，因此您需要打包必要的状态，以便从代码生成的最后一个位置继续。 结果相当怪异，如清单 8-4 所示。

```rust
enum Forward<T> { 1
 WaitingForReceive(ReceiveFuture<T>, Option<Sender<T>>), WaitingForSend(SendFuture<T>, Option<Receiver<T>>), 

} 

impl<T> Future for Forward<T> {
 type Output = (); 2
 fn poll(&mut self) -> Poll<Self::Output> { 

match self { 3 Forward::WaitingForReceive(recv, tx) => { 
enum Forward<T> { 1
 WaitingForReceive(ReceiveFuture<T>, Option<Sender<T>>), WaitingForSend(SendFuture<T>, Option<Receiver<T>>), 

} 

impl<T> Future for Forward<T> {
 type Output = (); 2
 fn poll(&mut self) -> Poll<Self::Output> { 
    match self { 3 	
      Forward::WaitingForReceive(recv, tx) => { 
        if let Poll::Ready((rx, v)) = recv.poll() {
          if let Some(v) = v {
            let tx = tx.take().unwrap(); 4
            *self = Forward::WaitingForSend(tx.send(v), Some(rx)); 5 
            // Try to make progress on sending.
            return self.poll(); 6 
          } else { 
            // No more items.
            Poll::Ready(())
          }
        } else {
          Poll::Pending
        } 
      } 
      Forward::WaitingForSend(send, rx) => {
        if let Poll::Ready(tx) = send.poll() {
          let rx = rx.take().unwrap();
             *self = Forward::WaitingForReceive(rx.receive(), Some(tx));
              // Try to make progress on receiving.
              return self.poll();
           } else {
             Poll::Pending
          } 
        } 
      } 
   } 
} 
```

*Listing 8-4: Manually implementing a channel-forwarding future*

您很少需要再用 Rust 编写这样的代码，但它提供了有关事物在幕后如何工作的重要见解，所以让我们来看看它。 首先，我们将未来的类型定义为枚举 1，我们将用它来跟踪我们当前正在等待的内容。 这是因为当我们返回 Poll::Pending 时，下一次对 poll 的调用将再次从函数的顶部开始。 我们需要某种方法来了解我们正在进行什么操作，以便我们知道要继续进行哪个操作。 此外，我们需要根据我们正在做的事情跟踪不同的信息：如果我们正在等待接收完成，我们需要保留 ReceiveFuture （本例中未显示其定义），以便 我们可以在下次轮询自己时轮询它，SendFuture 也是如此。 这里的选项可能也会让你觉得很奇怪； 我们很快就会回来讨论这些问题。

当我们实现 Future for Forward 时，我们将其输出类型声明为 () 2，因为这个 future 实际上不会返回任何内容。 相反，当 future 将所有内容从输入通道转发到输出通道时，它就会解析（没有结果）。 在更完整的示例中，转发类型的输出可能是结果，以便它可以将来自 receive() 和 send() 的错误传达给正在轮询转发完成情况的函数。 但这段代码已经足够复杂了，所以我们改天再讲。

当 Forward 被轮询时，它需要从上次停止的地方恢复，我们通过匹配当前在 self 3 中保存的枚举变量来找到这一点。无论我们进入哪个分支，第一步都是轮询阻止进度的 future 当前操作； 如果我们尝试接收，我们会轮询 ReceiveFuture，如果我们尝试发送，我们会轮询 SendFuture。 如果对 poll 的调用返回 Poll::Pending，那么我们就无法取得任何进展，并且我们自己返回 Poll::Pending。 但如果当前的未来已经解决，我们还有工作要做！

当其中一个内部 future 解析时，我们需要通过切换 self 中存储的枚举变量来更新当前操作。 为了做到这一点，我们必须摆脱 self 来调用 Receiver::receive 或 Sender::send——但我们不能这样做，因为我们拥有的只是 &mut self。 因此，我们将必须移动的状态存储在 Option 中，然后使用 Option::take 4 移出该状态。这很愚蠢，因为我们无论如何都要覆盖 self 5，因此 Options 将始终是 Some，但是 有时需要一些技巧才能让借阅检查员高兴。

最后，如果我们确实取得了进展，我们就会再次轮询自己 6，这样，如果我们可以立即在待处理的发送或接收上取得进展，我们就会这样做。 这实际上对于实现真正的 Future 特征时的正确性是必要的，我们稍后会讨论这一点，但现在将其视为一种优化。

我们只是手写了一个“状态机”：一种具有多种可能状态并在它们之间移动以响应特定事件的类型。 这是一个相当简单的状态机。 想象一下，对于需要额外中间步骤的更复杂的用例，必须编写这样的代码！

除了编写笨重的状态机之外，我们还必须知道 Sender::send 和 Receiver::receive 返回的 future 类型，以便我们可以将它们存储在我们的类型中。 如果这些方法返回 impl Future，我们将无法写出我们的变体的类型。 发送和接收方法还必须拥有发送者和接收者的所有权； 如果他们不这样做，他们返回的 future 的生命周期将与 self 的借用联系在一起，当我们从 poll 返回时，这将结束。 但这是行不通的，因为我们试图将这些未来存储在“自己”中。

**N O T E**  *您可能已经注意到接收器看起来很像迭代器的异步版本。 其他人也注意到了同样的事情，标准库正在为可以有意义地实现  poll_next 的类型专门添加一个特征。 最终，这些异步迭代器（通常称为流）最终可能会获得一流的语言支持，例如直接循环它们的能力！*

最终，这些代码很难编写、很难阅读、也很难更改。 例如，如果我们想添加错误处理，代码复杂性会显着增加。 幸运的是，有更好的方法！

### *async/await*

Rust 1.39 为我们提供了 async 关键字和密切相关的await 后缀运算符，我们在清单 8-3 的原始示例中使用了它们。 它们共同提供了一种更方便的机制来编写异步状态机，如清单 8-5 中的状态机。 具体来说，它们让您以一种看起来不像状态机的方式编写代码！

``` rust
async fn forward<T>(rx: Receiver<T>, tx: Sender<T>) {
    while let Some(t) = rx.next().await {
        tx.send(t).await;
    }
}
```
*Listing 8-5: Implementing a channel-forwarding future using *async* and *await*, repeated from Listing 8-3 *

如果您对 async 和 wait 没有太多经验，清单 8-4 和清单 8-5 之间的差异可能会让您了解为什么 Rust 社区如此兴奋地看到它们的落地。 但由于这是一本中级书籍，让我们更深入地了解这一短段代码如何取代更长的手动实现。 为此，我们首先需要讨论“生成器”——实现 async 和 wait 的机制。

#### Generators

简而言之，生成器是一段带有一些额外的编译器生成位的代码块，使其能够在中途停止或“屈服”其执行，然后从稍后上次产生的位置恢复。 以清单 8-3 中的前向函数为例。 想象一下，它到达了要发送的呼叫，但通道当前已满。 该函数无法再取得任何进展，但它也不能阻塞（毕竟这是非阻塞代码），因此它需要返回。 现在假设通道最终被清除，我们想要继续发送。 如果我们再次从顶部调用forward，它会再次调用next，我们之前尝试发送的项目将会丢失，所以这是不好的。 相反，我们将前转变成一个发电机。

每当前向生成器无法再取得进展时，它就需要将其当前状态存储在某个地方，以便当它的执行最终恢复时，它会在正确的位置以正确的状态恢复。 它通过编译器生成的关联数据结构保存状态，其中包含生成器在给定时间点的所有状态。 然后，该数据结构（也生成）上的方法允许生成器从存储在 &mut self 中的当前状态恢复，并在生成器再次无法取得进展时再次更新状态。

这种“返回但允许我稍后恢复”操作称为*yielding*，这实际上意味着它返回，同时保留一些额外的状态。 当我们稍后想要恢复对转发的调用时，我们调用生成器的已知入口点（*恢复方法*，这是异步生成器的轮询），并且生成器检查 self 中先前存储的状态来决定要做什么 下一个。 这与我们在清单 8-4 中手动执行的操作完全相同！ 换句话说，清单 8-5 中的代码与清单 8-6 中所示的假设代码松散地脱糖。

``` rust
generator fn forward<T>(rx: Receiver<T>, tx: Sender<T>) {
    loop {
        let mut f = rx.next();
        let r = if let Poll::Ready(r) = f.poll() { r } else { yield };
        if let Some(t) = r {
            let mut f = tx.send(t);
            let _ = if let Poll::Ready(r) = f.poll() { r } else { yield };
        } else { break Poll::Ready(()); }
	}
} 
```
*Listing 8-6: Desugaring *async*/*await* into a generator *

简而言之，生成器是一段带有一些额外的编译器生成位的代码块，使其能够在中途停止或“屈服”其执行，然后从稍后上次产生的位置恢复。 以清单 8-3 中的前向函数为例。 想象一下，它到达了要发送的呼叫，但通道当前已满。 该函数无法再取得任何进展，但它也不能阻塞（毕竟这是非阻塞代码），因此它需要返回。 现在假设通道最终被清除，我们想要继续发送。 如果我们再次从顶部调用forward，它会再次调用next，我们之前尝试发送的项目将会丢失，所以这是不好的。 相反，我们将前转变成一个发电机。

每当前向生成器无法再取得进展时，它就需要将其当前状态存储在某个地方，以便当它的执行最终恢复时，它会在正确的位置以正确的状态恢复。 它通过编译器生成的关联数据结构保存状态，其中包含生成器在给定时间点的所有状态。 然后，该数据结构（也生成）上的方法允许生成器从存储在 &mut self 中的当前状态恢复，并在生成器再次无法取得进展时再次更新状态。

这种“返回但允许我稍后恢复”操作称为*yielding*，这实际上意味着它返回，同时保留一些额外的状态。 当我们稍后想要恢复对转发的调用时，我们调用生成器的已知入口点（*恢复方法*，这是异步生成器的轮询），并且生成器检查 self 中先前存储的状态来决定要做什么 下一个。 这与我们在清单 8-4 中手动执行的操作完全相同！ 换句话说，清单 8-5 中的代码与清单 8-6 中所示的假设代码松散地脱糖。

> **THE SIZE OF GENERATORS** 
> 
> 用于支持生成器状态的数据结构必须能够在任何一个屈服点保持组合状态。 如果您的 async fn 包含 [u8; 8192]，这8KiB必须存储在生成器本身中。 即使您的 async fn 仅包含较小的局部变量，它也必须包含它等待的任何 future，因为它需要能够稍后在调用 poll 时轮询这样的 future。
>
> 这种嵌套意味着生成器以及基于异步函数和块的 future 可能会变得相当大，而代码中却没有任何可见的指示符表明大小已增加。 这反过来会影响程序的运行时性能，因为这些巨大的生成器可能必须在函数调用之间以及数据结构中和数据结构中进行复制，这相当于相当数量的内存复制。 事实上，您通常可以通过在应用程序的性能配置文件中查找 memcpy 函数花费的过多时间来确定基于生成器的 future 的大小何时影响性能！
>
> 然而，找到这些大型未来并不总是那么容易，并且通常需要手动识别长或复杂的异步函数链。 Clippy 将来可能会提供帮助，但在撰写本文时，您只能靠自己了。 当您确实找到一个特别大的 future 时，您有两个选择：您可以尝试减少异步函数所需的本地状态量，或者可以将 future 移动到堆（使用 Box::pin），以便移动 future 只需将指针移动到它即可。 后者是迄今为止最简单的方法，但它也引入了额外的分配和指针间接寻址。 您最好的选择通常是将有问题的未来放在堆上，衡量您的性能，然后使用性能基准来指导您。
### *Pin and Unpin*

我们还没有完全完成。 虽然生成器很简洁，但正如我到目前为止所描述的那样，这项技术也带来了挑战。 特别是，如果生成器（或者等效的异步块）中的代码引用局部变量，则不清楚会发生什么。 在清单 8-5 的代码中，如果下一条消息不能立即可用，则 rx.next() 返回的 future 必须持有对 rx 的引用，以便它知道当生成器下次恢复时在哪里重试。 当生成器屈服时，未来和未来包含的参考被隐藏在生成器内。 但如果发电机被移动，现在会发生什么？ 具体来说，请查看清单 8-7 中的代码，其中调用了前向。

``` rust
async fn try_forward<T>(rx: Receiver<T>, tx: Sender<T>) -> Option<impl Future>
{
    let mut f = forward(rx, tx);
    if f.poll().is_pending() { Some(f) } else { None }
}
```

*Listing 8-7: Moving a future after polling it*

try_forward 函数仅轮询一次转发，以在不阻塞的情况下转发尽可能多的消息。 如果接收方仍可能产生更多消息（即，如果它返回 Poll::Pending 而不是 Poll::Ready(None)），则通过将转发 future 返回给调用方，这些消息将推迟在稍后的某个时间转发， 它可能会选择在认为合适的时候再次进行轮询。

让我们根据目前为止对 async 和 wait 的了解来了解一下这里发生的情况。 当我们轮询正向生成器时，它会执行 while 循环未知次数，并最终在接收器结束时返回 Poll::Ready(()) ，否则返回 Poll::Pending 。 如果它返回 Poll::Pending，则生成器包含从 rx.next() 或 tx.send(t) 返回的 future。 这些 future 都包含对最初提供给转发的参数之一的引用（分别是 rx 和 tx），这些参数也必须存储在生成器中。 但是当 try_forward 返回整个生成器时，生成器的字段也会移动。 因此，rx 和 tx 不再驻留在内存中的相同位置，并且存储在隐藏的 future 中的引用不再指向正确的数据！

我们在这里遇到的是一种“自引用”数据结构的情况：既保存数据又保存对该数据的引用。 使用生成器，这些自引用结构非常容易构建，并且无法支持它们将对人体工程学造成重大打击，因为这意味着您将无法在任何屈服点保持引用。 Rust 中支持自引用数据结构的（巧妙的）解决方案以 Pin 类型和 Unpin 特征的形式出现。 简而言之，Pin 是一种包装类型，可防止包装类型被（安全）移动，而 Unpin 是一种标记特征，表示实现类型*可以*从 Pin 中安全删除。

#### Pin

这里有很多细微差别需要讨论，所以让我们从 Pin 包装器的具体使用开始。 清单 8-2 为您提供了 Future 特征的简化版本，但我们现在准备剥离一部分简化内容。 清单 8-8 显示了 Future 特征更接近其最终形式。

``` rust
trait Future {
    type Output;
    fn poll(self: Pin<&mut Self>) -> Poll<Self::Output>;
}
```

*Listing 8-8: A less simplified view of the *Future* trait with *Pin* *


特别是，此定义要求您对 Pin<&mut Self> 调用 poll。 一旦您拥有 Pin 图背后的价值，就构成了一份合同，该价值将永远不会再移动。 这意味着您可以随心所欲地在内部构建自我引用，就像您想要的生成器一样。

**NOTE** *While* *Future* *makes use of* *Pin**,* *Pin* *is not tied to the* *Future* *trait—you can use* *Pin* *for* any *self-referential data structure.* 

但是如何获得 Pin 来调用投票呢？ 而Pin如何保证所包含的值不会移动呢？ 为了了解这个魔法是如何工作的，让我们看看 std::pin::Pin 的定义及其一些关键方法，如清单 8-9 所示。

``` rust
struct Pin<P> { pointer: P }
impl<P> Pin<P> where P: Deref {
  pub unsafe fn new_unchecked(pointer: P) -> Self;
}
impl<'a, T> Pin<&'a mut T> {
  pub unsafe fn get_unchecked_mut(self) -> &'a mut T;
}
impl<P> Deref for Pin<P> where P: Deref {
  type Target = P::Target;
  fn deref(&self) -> &Self::Target;
}
```

*Listing 8-9: *std::pin::Pin* and its key methods *

这里有很多东西需要解开，在所有的部分都有意义之前，我们必须仔细检查清单 8-9 中的定义，所以请耐心等待。

首先，您会注意到 Pin 持有*指针类型*。 也就是说，它不是直接保存一些 T，而是保存一个类型 P，通过 Deref 取消引用到 T。这意味着您将拥有一个 Pin<Box<MyType>> 或者 Pin<Rc<MyType>> 或者 Pin<&mut MyType>。 这种设计的原因很简单——Pin 的主要目标是确保一旦将 T 放在 Pin 后面，T 就不会移动，因为这样做可能会使 T 中存储的自引用无效。如果 Pin 刚刚按住 直接输入 T，然后简单地移动 Pin 就足以使该不变量无效！ 在本节的其余部分中，我将 P 称为 *pointer* 类型，将 T 称为 *target* 类型。

接下来，请注意 Pin 的构造函数 new_unchecked 是不安全的。 这是因为编译器无法实际检查指针类型是否确实承诺所指向的（目标）类型不会再次移动。 例如，考虑堆栈上的变量 foo。 如果 Pin 的构造函数是安全的，我们可以执行 Pin::new(&mut foo)，调用需要 Pin<&mut Self> 的方法（因此假设 Self 不会再次移动），然后删除 Pin。 此时，我们可以随意修改 foo，因为它不再是借用的，包括移动它！ 然后我们可以再次固定它并调用相同的方法，这并不意味着它第一次构建的任何自引用指针现在都将无效。

> **PIN CONSTRUCTOR SAFETY** 
> 
> Pin 的构造函数不安全的另一个原因是它的安全性取决于本身安全的特征的实现。 例如， Pin<P> 实现 get_unchecked_mut 的方式是使用 P 的 DerefMut::deref_mut 实现。 虽然对 get_unchecked_mut 的调用是不安全的，但 P 的 impl DerefMut 却不是。 然而它收到一个 &mut self，因此可以自由（并且没有不安全代码）移动 T 。 同样的事情也适用于 Drop 。 因此，Pin::new_unchecked 的安全要求不仅是指针类型不会让目标类型再次移动（如 Pin<&mut T> 示例中所示），而且其 Deref、DerefMut 和 Drop 实现也不会再次移动。 将指向的值移到它们收到的 &mut self 后面。

然后我们使用 get_unchecked_mut 方法，它为您提供对 Pin 指针类型后面的 T 的可变引用。 这种方法也是不安全的，因为一旦我们给出 &mut T，调用者必须保证它不会使用 &mut T 来移动 T 或以其他方式使其内存无效，以免任何自引用无效。 如果这个方法不是不安全的话，调用者可以
调用一个采用 Pin<&mut Self> 的方法，然后在两个 Pin<&mut _> 上调用 get_unchecked_mut 的安全变体，然后使用 mem::swap 交换 Pin 后面的值。 如果我们随后在任一 Pin 上调用再次采用 Pin<&mut Self> 的方法，则将违反 Self 未移动的假设，并且它存储的任何内部引用都将无效！

也许令人惊讶的是，Pin<P> 总是实现 Deref<Target = T>，而且这是完全安全的。 原因是 &T 不允许您在不编写其他不安全代码（例如 UnsafeCell，我们将在第 9 章中讨论）的情况下移动 T。 这是一个很好的例子，说明了为什么不安全块的范围不仅仅限于它包含的代码。 如果您在应用程序的某个部分编写了一些代码，使用 UnsafeCell（不安全地）替换了 & 后面的 T，那么 *可能* 是 &T 最初来自 Pin<&mut T>，并且您现在违反了 Pin 后面的 T 可能永远不会移动，即使您不安全地替换 &T 的地方甚至没有提到 Pin！

**N O T E** *如果您在阅读本章时浏览过* *Pin* *文档，您可能已经注意到* *Pin::set**，它需要一个* *&mut self* *和一个* *::Target* * 并安全地更改 * *Pin** 后面的值。 这是可能的，因为 * *set* * 不会返回先前固定的值 - 它只是将其放置到位并在那里存储新值。 因此，它不会违反固定不变量：旧值在放置在 a* *Pin* * 之外之后从未被访问过。*

#### Unpin: The Key to Safe Pinning

此时您可能会问：既然获取可变引用无论如何都是不安全的，为什么不让 Pin 直接持有 T 呢？ 也就是说，您不需要通过指针类型进行间接寻址，而是可以为 get_unchecked_mut 制定契约，只有在没有移动 Pin 的情况下才可以安全地调用它。 这个问题的答案在于指针设计所实现的 Pin 的巧妙安全使用。 回想一下，我们首先想要 Pin 的全部原因是这样我们可以拥有可能包含对自身的引用（如生成器）的目标类型，并为它们的方法提供目标类型没有移动的保证，从而保证内部的自我 参考文献仍然有效。 Pin 让我们可以使用类型系统来强制执行该保证，这很棒。 但不幸的是，就目前的设计而言，Pin 的使用非常笨拙。 这是因为它总是需要不安全的代码，即使您正在使用不包含任何自引用的目标类型，因此也不关心它是否已被移动。

这就是标记特征 Unpin 发挥作用的地方。 类型的 Unpin 实现只是断言该类型在用作目标类型时可以安全地移出 Pin。 也就是说，该类型承诺永远不会使用 Pin 的任何保证，即当用作目标类型时，指示对象不会再次移动，因此这些保证可能会被打破。 Unpin 是一种自动特征，就像 Send 和 Sync 一样，因此编译器会针对仅包含 Unpin 成员的任何类型自动实现。 只有明确选择不取消固定的类型（如生成器）和包含这些类型的类型才会被 !Unpin。

For target types that are Unpin, we can provide a much simpler safe interface to Pin, as shown in Listing 8-10. 

``` rust
impl<P> Pin<P> where P: Deref, P::Target: Unpin {
    pub fn new(pointer: P) -> Self;
}
impl<P> DerefMut for Pin<P> where P: DerefMut, P::Target: Unpin {
    fn deref_mut(&mut self) -> &mut Self::Target;
}
```

*Listing 8-10: The safe API to *Pin* for *Unpin* target types* 

To make sense of the safe API in Listing 8-10, think about the safety requirements of the unsafe methods from Listing 8-9: the function Pin::new_unchecked is unsafe because the caller must promise that the referent cannot be moved outside of the Pin, and that the implementations of Deref, DerefMut, and Drop for the pointer type do not move the referent through the reference they receive. Those requirements are there to ensure that once we give out a Pin to a T, we never move that T again. But if the T is Unpin, it has declared that it does not care if it is moved even if it was previously pinned, so it’s fine if the caller does not satisfy any of those requirements! 

Similarly, get_unchecked_mut is unsafe because the caller must guarantee that it doesn’t move the T out of the &mut T—but with T: Unpin, T has declared that it’s fine being moved even after being pinned, so that safety require- ment is no longer important. This means that for Pin<P> where P::Target: Unpin, we can simply provide safe variants of both those methods (DerefMut being the safe version of get_unchecked_mut). In fact, we can even provide a Pin::into_inner that simply gives back the owned P if the target type is Unpin, since the Pin is essentially irrelevant! 

#### Ways of Obtaining a Pin

With our new understanding of Pin and Unpin, we can now make progress toward using the new Future definition from Listing 8-8 that requires Pin<&mut Self>. The first step is to construct the required type. If the future type is Unpin, that step is easy—we just use Pin::new(&mut future). If it is not Unpin, we can pin the future in one of two main ways: by pinning to the heap or pinning to the stack. 

Let’s start with pinning to the heap. The primary contract of Pin is that once something has been pinned, it cannot move. The pinning API takes care of honoring that contract for all methods and traits on Pin, so the main role of any function that constructs a Pin is to ensure that if the Pin *itself* moves, the referent value does not move too. The easiest way to ensure that is to place the referent on the heap, and then place just a pointer to the refer- ent in the Pin. You can then move the Pin to your heart’s delight, but the tar- get will remain where it was. This is the rationale behind the (safe) method Box::pin, which takes a T and returns a Pin<Box<T>>. There’s no magic to it; it simply asserts that Box follows the Pin constructor, Deref, and Drop contracts. 

> **UNPIN BOX** 
> 
> While we’re on the topic of Box, take a look at the implementation of Unpin for Box . The Box type unconditionally implements Unpin for any T, even if that T is not Unpin . This might strike you as odd, given the earlier assertion that Unpin is an auto-trait that is generally implemented for a type only if all of the type’s members are also Unpin . Box is an exception to this for the same reason that it can provide a safe Pin constructor: if you move a Box<T>, you do not move the T . In other words, the unconditional implementation asserts that you can move a Box<T> out of a Pin even if T cannot be moved out of a Pin . Note, however, that this does not enable you to move a T that is !Unpin out of a Pin<Box<T>> . 

The other option, pinning to the stack, is a little more involved, and at the time of writing requires a smidgen of unsafe code. We have to ensure that the pinned value cannot be accessed after the Pin with a &mut to it has been dropped. We accomplish that by shadowing the value as shown in the macro in Listing 8-11 or by using one of the crates that provide exactly this macro. One day it may even make it into the standard library! 

``` rust
macro_rules! pin_mut {
    ($var:ident) => {
        let mut $var = $var;
        let mut $var = unsafe { Pin::new_unchecked(&mut $var) };
    }
} 
```

Listing 8-11: Macro for pinning to the stack 

By taking the name of the variable to pin to the stack, the macro ensures that the caller has the value it wants to pin somewhere on the stack already. The shadowing of \$var ensures that the caller cannot drop the Pin and continue to use the unpinned value (which would breach the Pin contract for any target type that’s !Unpin). By moving the value stored in $var, the macro also ensures that the caller cannot drop the $var bind- ing the macro declarations without also dropping the original variable. Specifically, without that line, the caller could write (note the extra scope): 

``` rust
let foo = /* */; { pin_mut!(foo); foo.poll() }; foo.mut_self_method();
```

Here, we give a pinned instance of foo to poll, but then we later use a &mut to foo without a Pin, which violates the Pin contract. With the extra reas- signment, on the other hand, that code would also move foo into the new scope, rendering it unusable after the scope ends. 

Pinning on the stack therefore requires unsafe code, unlike Box::pin, but avoids the extra allocation that Box introduces and also works in no_std environments. 

#### Back to the Future

We now have our pinned future, and we know what that means. But you may have noticed that none of this important pinning stuff shows up in most asynchronous code you write with async and await. And that’s because the compiler hides it from you. 

Think back to when we discussed Listing 8-5, when I told you that <expr>.await desugars into something like: 

``` rust
loop { if let Poll::Ready(r) = expr.poll() { break r } else { yield } }
```

That was an ever-so-slight simplification because, as we’ve seen, you can call Future::poll only if you have a Pin<&mut Self> for the future. The desug- aring is actually a bit more sophisticated, as shown in Listing 8-12. 

``` rust
match expr {
	mut pinned => loop { 
		match unsafe { Pin::new_unchecked(&mut pinned) }.poll() { Poll::Ready(r) => break r,
 Poll::Pending => yield, 

		} 
	} 
} 
```

*Listing 8-12: A more accurate desugaring of <expr>.await*

The match 1 is a neat shorthand to not only ensure that the expansion remains a valid expression, but also move the expression result into a variable that we can then pin on the stack. Beyond that, the main new addition is the call to Pin::new_unchecked 2. That call is safe because for the containing async block to be polled, it must already be pinned due to the signature of Future::poll. And the async block was polled for us to reach the call to Pin::new_unchecked, so the generator state is pinned. Since pinned is stored in the generator that corresponds to the async block (it must be so that yield will resume correctly), we know that pinned will not move again. Furthermore, pinned is not accessible except through a Pin once we’re in the loop, so no code is able to move out of the value in pinned. Thus, we meet all the safety requirements of Pin::new_unchecked, and the code is safe. 

## Going to Sleep

We went pretty deep into the weeds with Pin, but now that we’re out the other side, there is another issue around futures that may have been mak- ing your brain itch. If a call to Future::poll returns Poll::Pending, you need something to call poll again at a later time to check whether you can make progress yet. That something is usually called the *executor*. Your executor could be a simple loop that polls all the futures you are waiting on until they’ve all returned Poll::Ready, but that would burn a lot of CPU cycles you could probably have used for other, more useful things, like running your web browser. Instead, we want the executor to do whatever useful work it can do, and then go to sleep. It should stay asleep until one of the futures can make progress, and only then wake up to do another pass, before going to sleep again. 

### *Waking Up*

The condition that determines when to check back with a given future var- ies widely. It might be “when a network packet arrives on this port,” “when the mouse cursor moves,” “when someone sends on this channel,” “when the CPU receives a particular interrupt,” or even “after this much time has passed.” On top of that, developers can write their own futures that wrap multiple other futures, and thus, they may have several wake-up conditions. Some futures may even introduce their own entirely custom wake events. 

To accommodate these many use cases, Rust introduces the notion of a Waker: a way to wake the executor to signal that progress can be made. The Waker is what makes the whole machinery around futures work. The executor constructs a Waker that integrates with the mechanism the executor uses to go to sleep, and passes the Waker in to any Future it polls. How? With the addi- tional parameter to Future::poll that I’ve hidden from you so far. Sorry about that. Listing 8-13 gives the final and true definition for Future—no more lies! 

``` rust
 trait Future {
	 type Output;
	 fn poll(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output>;
 }
```
Listing 8-13: The actual *Future* trait with *Context* 

The &mut Context contains the Waker. The argument is a Context, not a Waker directly, so that we can augment the asynchronous ecosystem with additional context for futures should that be deemed necessary. 

The primary method on Waker is wake (and the by-reference variant wake _by_ref), which should be called when the future can again make progress. The wake method takes no arguments, and its effects are entirely defined by the executor that constructed the Waker. You see, Waker is secretly generic over the executor. Or, more precisely, whatever constructed the Waker gets to dictate what happens when Waker::wake is called, when a Waker is cloned, and when a Waker is dropped. This all happens through a manually implemented vtable, which functions similarly to the dynamic dispatch we discussed way back in Chapter 2. 

It’s a somewhat involved process to construct a Waker, and the mechan- ics of it aren’t all that important for using one, but you can see the building blocks in the RawWakerVTable type in the standard library. It has a constructor that takes the function pointers for wake and wake_by_ref as well as Clone and Drop. The RawWakerVTable, which is usually shared among all of an executor’s wakers, is bundled up with a raw pointer intended to hold data specific to each Waker instance (like which future it’s for) and is turned into a RawWaker. That is in turn passed to Waker::from_raw to produce a safe Waker that can be passed to Future::poll. 

### *Fulfilling the Poll Contract*

So far we’ve skirted around what a future actually does with a Waker. The idea is fairly simple: if Future::poll returns Poll::Pending, it is the future’s responsibility to ensure that *something* calls wake on the provided Waker when the future is next able to make progress. Most futures uphold this property by returning Poll::Pending only if some other future also returned Poll::Pending; in this way, it trivially fulfills the contract of poll since the inner future must follow that same contract. But there can’t be turtles all the way down. At some point, you reach a future that does not poll other futures but instead does something like write to a network socket or attempt to receive on a channel. These are commonly referred to as *leaf futures* since they have no children. A leaf future has no inner future but instead directly represents some resource that may not yet be ready to return a result. 

**N O T E** *The poll contract is the reason why the recursive* *poll* *call* 6 *back in Listing 8-4 is necessary for correctness.* 

Leaf futures typically come in one of two shapes: those that wait for events that originate within the same process (like a channel receiver), and those that wait for events external to the process (like a TCP packet read). Those that wait for internal events all tend to follow the same pattern: store the Waker where the code that will wake you up can find it, and have that code call wake on the Waker when it generates the relevant event. For example, consider a leaf future that has to wait for a message on an in-memory chan- nel. It stores its Waker inside the part of the channel that is shared between the sender and the receiver and then returns Poll::Pending. When a sender later comes along and injects a message into the channel, it notices the Waker left there by the waiting receiver and calls wake on the Waker before returning from send. Now the receiver is awoken, and the poll contract is upheld. 

Leaf futures that deal with external events are more involved, as the code that generates the event they’re waiting for knows nothing of futures or wakers. Most often the generating code is the operating system kernel, which knows when a disk is ready or a timer expires, but it could also be a C library that invokes a callback into Rust when an operation completes or some other such external entity. A leaf future wrapping an external resource like this could spin up a thread that executes a blocking system call (or waits for the C callback) and then use the internal waking mecha- nism, but that would be wasteful; you would spin up a thread every time an operation had to wait and be left with lots of single-use threads sitting around waiting for things. 

Instead, executors tend to provide implementations of leaf futures that communicate behind the scenes with the executor to arrange for the appropriate interaction with the operating system. How exactly this is orchestrated depends on the executor and the operating system, but roughly speaking the executor keeps track of all the event sources that it should listen for the next time it goes to sleep. When a leaf future realizes it must wait for an external event, it updates that executor’s state (which it knows about since it’s provided by the executor crate) to include that exter- nal event source alongside its Waker. When the executor can no longer make progress, it gathers all of the event sources the various pending leaf futures are waiting for and does a big blocking call to the operating system, telling it to return when *any* of the resources the leaf futures are waiting on have a new event. On Linux, this is usually achieved with the epoll system call; Windows, the BSDs, macOS, and pretty much every other operating system provide similar mechanisms. When that call returns, the executor calls wake on all the wakers associated with event sources that the operating system reported events for, and thus the poll contract is fulfilled. 

**N O T E** *A* reactor *is the part of an executor that leaf futures register event sources with and that the executor waits on when it has no more useful work to do. It is possible to separate the executor and the reactor, though bundling them together often improves performance as the two can be co-optimized more readily.* 

A knock-on effect of the tight integration between leaf futures and the executor is that leaf futures from one executor crate often cannot be used with a different executor. Or at least, they cannot be used unless the leaf future’s executor is *also* running. When the leaf future goes to store its Waker and register the event source it’s waiting for, the executor it was built against needs to have that state set up and needs to be running so that the event source will actually be monitored and wake eventually called. There are ways around this, such as having leaf futures spawn an executor if one is not already running, but this is not always advisable as it means that an application can transparently end up with multiple executors run- ning at the same time, which can reduce performance and mean you must inspect the state of multiple executors when debugging. 

Library crates that wish to support multiple executors have to be generic over their leaf resources. For example, instead of using a particular executor’s TcpStream or File future type, a library can store a generic T: AsyncRead + AsyncWrite. However, the ecosystem has yet to settle on exactly what these traits should look like and which traits are needed, so for the moment it’s fairly diffi- cult to make code truly generic over the executor. For example, while AsyncRead and AsyncWrite are somewhat common across the ecosystem (or can be easily adapted if necessary), no traits currently exist for running a future in the background (*spawning*, which we’ll discuss later) or for representing a timer. 

### *Waking Is a Misnomer*

You may already have realized that Waker::wake doesn’t necessarily seem to *wake* anything. For example, for external events (as described in the previ- ous section), the executor is already awake, and it might seem silly for it to then call wake on a Waker that belongs to that executor anyway! The reality is that Waker::wake is a bit of a misnomer—in reality, it signals that a particular future is *runnable*. That is, it tells the executor that it should make sure to poll this particular future when it gets around to it rather than go to sleep again, since this future can make progress. This might wake the executor if it is currently sleeping so it will go poll that future, but that’s more of a side effect than its primary purpose. 

It is important for the executor to know which futures are runnable for two reasons. First, it needs to know when it can stop polling a future and go to sleep; it’s not sufficient to just poll each future until it returns Poll::Pending, since polling a later future might make it possible to progress an earlier future. Consider the case where two futures bounce messages back and forth on channels to one another. When you poll one, the other becomes ready, and vice versa. In this case, the executor should never go to sleep, as there is always more work to do. 

Second, knowing which futures are runnable lets the executor avoid polling futures unnecessarily. If an executor manages thousands of pending futures, it shouldn’t poll all of them just because an event made one of them runnable. If it did, executing asynchronous code would get very slow indeed. 

### *Tasks and Subexecutors*

The futures in an asynchronous program form a tree: a future may contain any number of other futures, which in turn may contain other futures, all the way down to the leaf futures that interact with wakers. The root of each tree is the future you give to whatever the executor’s main “run” function is. These root futures are called *tasks*, and they are the only point of contact between the executor and the futures tree. The executor calls poll on the task, and from that point forward the code of each contained future must figure out which inner future(s) to poll in response, all the way down to the relevant leaf. 

Executors generally construct a separate Waker for each task they poll so that when wake is later called, they know which task was just made runnable and can mark it as such. That is what the raw pointer in RawWaker is for—to dif- ferentiate between tasks while sharing the code for the various Waker methods. 

When the executor eventually polls a task, that task starts running from the top of its implementation of Future::poll and must decide from there how to get to the future deeper down that can now make progress. Since each future knows only about its own fields, and nothing about the whole tree, this all happens through calls to poll that each traverse one edge in the tree. 

The choice of which inner future to poll is often obvious, but not always. In the case of async/await, the future to poll is the one we’re blocked waiting for. But in a future that waits for the first of several futures to make prog- ress (often called a *select*), or for all of a set of futures (often called a *join*), there are many options. A future that has to make such a choice is basically a subexecutor. It could poll all of its inner futures, but doing so could be quite wasteful. Instead, these subexecutors often wrap the Waker they receive in poll’s Context with their own Waker type before they invoke poll on any inner future. In the wrapping code, they mark the future they just polled as runnable in their own state before they call wake on the original Waker. That way, when the executor eventually polls the subexecutor future again, the subexecutor can consult its own internal state to figure out which of its inner futures caused the current call to poll, and then only poll those. 

> **BLOCKING IN ASYNC CODE** 
> 
> You must be careful about calling synchronous code from asynchronous code, since any time an executor thread spends executing the current task is time it’s not spending running other tasks . If a task occupies the current thread for a prolonged period of time without yielding back to the executor, which might happen when executing a blocking system call (like std::sync::sleep), running a subexecutor that doesn’t yield occasionally, or running in a tight loop with no awaits, then other tasks the current executor thread is responsible for won’t get to run during that time . Usually, this manifests as long delays between when certain tasks can make progress (such as when a client connects) and when they actually get to execute . 
> 
> Some multithreaded executors implement work-stealing techniques, where idle executor threads steal tasks from busy executor threads, but this is more of a mitigation than a solution . Ultimately, you could end up in a situation where all the executor threads are blocked, and thus no tasks get run until one of the blocking operations completes . 
> 
> In general, you should be very careful with executing compute-intensive operations or calling functions that could block in an asynchronous context . Such operations should either be converted to asynchronous operations where possible or executed on dedicated threads that then communicate using a primitive that does support asynchrony, like a channel . Some executors also provide mechanisms for indicating that a particular segment of asynchronous code might block or for yielding voluntarily in the context of loops that might otherwise not yield, which can compose part of the solution . A good rule of thumb is that no future should be able to run for more than 1 ms without return- ing Poll::Pending . 

## Tying It All Together with spawn

When working with asynchronous executors, you may come across an operation that spawns a future. We’re now in a position to explore what that means! Let’s do so by way of example. First, consider the simple server implementation in Listing 8-14. 

``` rust
 async fn handle_client(socket: TcpStream) -> Result<()> {
	 // Interact with the client over the given socket.
 } 
 async fn server(socket: TcpListener) -> Result<()> {
	 while let Some(stream) = socket.accept().await? {
		 handle_client(stream).await?;
	 }
 } 
```

Listing 8-14: Handling connections sequentially 

顶层服务器功能本质上是一个大未来，它监听新连接并在新连接到达时执行某些操作。 你把这个 future 交给执行者并说“运行这个”，因为你不希望你的程序立即退出，所以你可能会在那个 future 上拥有执行者块。 也就是说，对执行器运行服务器 future 的调用将不会返回，直到服务器 future 解析为止，这可能永远不会返回（另一个客户端可能总是稍后到达）。

现在，每当有新的客户端连接进入时，清单 8-14 中的代码就会创建一个新的 future（通过调用 handle_client）来处理该连接。 由于处理本身就是未来，我们等待它，然后继续下一个客户端连接。

这种方法的缺点是我们一次只能处理一个连接——没有并发性。 一旦服务器接受连接，handle_client函数就会被调用，并且由于我们等待它，所以我们不会再次循环，直到handle_client的返回future解析（大概是当该客户端离开时）。

我们可以通过保留一组所有客户端 future 并让服务器接受新连接的循环也检查所有客户端 future 以查看是否有任何可以取得进展来改进这一点。 清单 8-15 显示了它的样子。

``` rust
 async fn server(socket: TcpListener) -> Result<()> {
	 let mut clients = Vec::new();
	 loop {
		 poll_client_futures(&mut clients)?;
		 if let Some(stream) = socket.try_accept()? {
			 clients.push(handle_client(stream));
		 }
	  }
 }   
```

Listing 8-15: Handling connections with a manual executor 

这至少可以同时处理许多连接，但相当复杂。 它也不是很高效，因为代码现在忙于循环，在处理我们已有的连接和接受新连接之间切换。 而且它必须每次检查每个连接，因为它不知道哪些连接可以取得进展（如果有的话）。 它也不能在任何时候等待，因为这会阻止其他未来取得进展。 您可以实现自己的唤醒器，以确保代码只轮询可以取得进展的 future，但最终这将沿着开发您自己的迷你执行器的道路前进。

坚持只为服务器执行一项任务（内部包含所有客户端连接的未来）的另一个缺点是服务器最终会成为单线程。 只有一个任务，要轮询它，代码必须持有对该任务的未来的独占引用（轮询采用 Pin<&mut Self>），一次只有一个线程可以持有该引用。

解决方案是让每个客户端未来都有自己的任务，并将其留给执行器在所有任务之间进行复用。 你猜对了，你通过孕育未来来做到这一点。 执行器将继续阻塞服务器的 future，但如果它无法在该 future 上取得进展，它将使用其执行机制同时在幕后的其他任务上取得进展。 最重要的是，如果执行器是多线程的并且您的客户端 future 是 Send，它可以并行运行它们，因为它可以同时保存单独任务的 &muts。 清单 8-16 给出了一个示例。

``` rust
async fn server(socket: TcpListener) -> Result<()> {
    while let Some(stream) = socket.accept().await? {
        // Spawn a new task with the Future that represents this client.
        // The current task will continue to just poll for more connections
        // and will run concurrently (and possibly in parallel) with handle_client.
        spawn(handle_client(stream));
	} } 
```
Listing 8-16: Spawning futures to create more tasks that can be polled concurrently 

当你生成一个 future 并使其成为一项任务时，这有点像生成一个线程。 future 继续在后台运行，并与分配给执行器的任何其他任务同时复用。 但是，与生成的线程不同，生成的任务仍然依赖于执行程序的轮询。 如果执行器停止运行，无论是因为您删除了它，还是因为您的代码不再运行执行器的代码，这些生成的任务将停止进展。 在服务器示例中，想象一下如果主服务器 future 由于某种原因解析会发生什么。 由于执行器已将控制权返回给您的代码，因此它无法继续执行任何操作。 多线程执行器通常会生成后台线程，即使执行器将控制权交还给用户的代码，这些线程也会继续轮询任务，但并非所有执行器都会这样做，因此在依赖该行为之前请检查您的执行器！

## 总结

在本章中，我们了解了 Rust 中可用的异步构造的幕后情况。 我们已经了解了编译器如何实现生成器和自引用类型，以及为什么这项工作对于支持我们现在所知的 async/await 是必要的。 我们还探讨了 future 是如何执行的，以及唤醒器如何允许执行器在任务之间进行多路复用，而在任何给定时刻只有其中一些任务可以取得进展。 在下一章中，我们将解决 Rust 中可能最深入、讨论最多的领域：不安全代码。 深吸一口气，然后翻页。