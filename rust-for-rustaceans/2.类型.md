现在基础知识已经搞清楚了，我们来看看 Rust 的类型系统。 我们将跳过 Rust 编程语言中介绍的基础知识，而是首先深入了解不同类型在内存中的布局、特征和特征边界的来龙去脉、存在类型以及使用类型的规则 跨越板条箱边界。

## 内存中的类型

每个 Rust 值都有一个类型。 正如我们将在本章中看到的，类型在 Rust 中具有多种用途，但它们最基本的作用之一是告诉您如何解释内存位。 例如，位序列 0b10111101（以十六进制表示法写为 0xBD）本身没有任何意义，除非您为其分配类型。 当在类型 u8 下解释时，该位序列是数字 189。当在类型 i8 下解释时，它是 –67。 当您定义自己的类型时，编译器的工作是确定已定义类型的每个部分在该类型的内存表示中的位置。 结构体的每个字段出现在位序列中的什么位置？ 您的枚举的判别式存储在哪里？ 当您开始编写更高级的 Rust 代码时，了解此过程的工作原理非常重要，因为这些细节会影响代码的正确性和性能。

***对齐***

在讨论如何确定类型在内存中的表示之前，我们首先需要讨论*对齐*的概念，它规定了类型的字节可以存储的位置。 一旦确定了类型的表示形式，您可能会认为可以采用任意内存位置并将存储在那里的字节解释为该类型。 虽然这在理论上是正确的，但实际上硬件也限制了给定类型的放置位置。 最明显的例子是指针指向*字节*，而不是*位*。 如果您从计算机内存的第 4 位开始放置一个 T 类型的值，您将无法引用它的位置； 您可以创建仅指向字节 0 或字节 1（位 8）的指针。 因此，所有值，无论其类型如何，都必须从字节边界开始。 我们说所有值必须至少是“字节对齐”的——它们必须放置在 8 位的倍数的地址处。

有些值具有比字节对齐更严格的对齐规则。 在CPU和内存系统中，内存通常以大于单个字节的块的形式进行访问。 例如，在 64 位 CPU 上，大多数值以 8 字节（64 位）块的形式访问，每个操作都从 8 字节对齐的地址开始。 这称为 CPU 的“字大小”。 然后，CPU 使用一些巧妙的方法来处理读取和写入较小的值或跨越这些块边界的值。

在可能的情况下，您希望确保硬件可以以其“本机”对齐方式运行。 要了解原因，请考虑如果尝试读取从 8 字节块中间开始的 i64（即指向它的指针不是 8 字节对齐）会发生什么情况。 硬件必须执行两次读取，一次从第一个块的后半部分读取 i64 的开头，一次从第二个块的前半部分读取 i64 的其余部分，然后进行拼接 结果在一起。 这不是很有效。 由于该操作分布在对底层内存的多次访问中，因此如果您正在读取的内存被不同的线程同时写入，您也可能会得到奇怪的结果。 您可能会在其他线程写入发生之前读取前 4 个字节，然后再读取第二个 4 个字节，从而导致值损坏。

对未对齐数据的操作称为“未对齐访问”，可能会导致性能不佳和并发问题。 因此，许多 CPU 操作要求或强烈希望它们的参数“自然对齐”。 自然对齐的值是其对齐与其大小相匹配的值。 因此，例如，对于 8 字节加载，提供的地址需要是 8 字节对齐的。

由于对齐访问通常更快并且提供更强的一致性语义，因此编译器会尽可能地利用它们。 它通过为每种类型提供一个根据其包含的类型计算的对齐方式来实现这一点。 内置值通常与其大小对齐，因此 u8 是字节对齐的，u16 是 2 字节对齐的，u32 是 4 字节对齐的，而 u64 是 8 字节对齐的。 复杂类型（包含其他类型的类型）通常会被分配它们所包含的任何类型的最大对齐方式。 例如，包含 u8、u16 和 u32 的类型将由于 u32 而进行 4 字节对齐。

***布局***

现在您了解了对齐，我们可以探索编译器如何决定类型的内存中表示（称为“布局”）。 默认情况下，正如您很快就会看到的，Rust 编译器对其如何布局类型提供了很少的保证，这使得理解基本原理的起点很差。 幸运的是，Rust 提供了一个 repr 属性，您可以将其添加到类型定义中，以请求该类型的特定内存中表示。 如果您确实看到过的话，您将看到的最常见的一个是 repr(C)。 顾名思义，它以与 C 或 C++ 编译器布局相同类型的方式兼容的方式布局类型。 这在编写使用外部函数接口与其他语言交互的 Rust 代码时非常有用，我们将在第 11 章中讨论这一点，因为 Rust 将生成与其他语言编译器的期望相匹配的布局。 由于 C 布局是可预测的并且不会发生更改，因此如果您正在使用指向类型的原始指针，或者如果您需要在已知具有相同属性的两种不同类型之间进行转换，则 repr(C) 在不安全的上下文中也很有用 字段。 当然，它非常适合我们迈出布局算法的第一步。

*另一个有用的表示是* *repr(transparent)**，它只能用于具有单个字段的类型，并且保证外部类型的布局与内部类型的布局完全相同。 这与“newtype”模式结合起来会很方便，在“newtype”模式中，您可能希望对某些 * *struct A* * 和 * *struct NewA(A)* * 的内存表示进行操作，就好像它们是相同的一样。 如果没有* *repr(transparent)**，Rust 编译器不保证它们将具有相同的布局。*

那么，让我们看看编译器如何使用 repr(C) 布局特定类型：清单 2-1 中的 Foo 类型。 您认为编译器会如何将其放置在内存中？

```
#[repr(C)]
struct Foo {
  tiny: bool,
  normal: u32,
  small: u8,
  long: u64,
  short: u16,
}
```

*Listing 2-1: Alignment affects layout.*

首先，编译器看到字段tiny，其逻辑大小为1位（真或假）。 但由于 CPU 和内存以字节为单位进行操作，因此tiny 在内存表示中被赋予 1 个字节。 接下来，normal是4字节类型，所以我们希望它是4字节对齐的。 但即使 Foo 是对齐的，我们分配给tiny的1个字节也会使normal错过它的对齐。 为了纠正这个问题，编译器将 3 个字节的 *padding*（具有不确定值的字节在用户代码中被忽略）插入到tiny 和 normal 之间的内存表示中。 填充中没有值，但它确实占用了空间。

对于下一个字段（small），对齐很简单：它是一个 1 字节值，结构中的当前字节偏移量是 1 + 3 + 4 = 8。这已经是字节对齐的，因此small可以在正常之后立即进行。 不过，过了很长一段时间，我们又遇到了问题。 现在我们已经将 1 + 3 + 4 + 1 = 9 个字节放入 Foo 中。 如果 Foo 对齐，那么 long 就不是我们想要的 8 字节对齐方式，因此我们必须插入另外 7 个字节的填充以使 long 再次对齐。 这也方便地确保了最后一个字段（short）所需的 2 字节对齐，使总数达到 26 字节。 现在我们已经遍历了所有字段，我们还需要确定 Foo 本身的对齐方式。 这里的规则是使用 Foo 的任何字段的最大对齐方式，由于 long，该对齐方式将是 8 个字节。 因此，为了确保 Foo 在放入数组时保持对齐，编译器会添加最后 6 个字节的填充，以使 Foo 的大小是其 32 字节对齐的倍数。

现在我们准备摆脱 C 的遗留，并考虑如果我们不使用清单 2-1 中的 repr(C)，布局会发生什么。 C 表示的主要限制之一是它要求我们按照原始结构定义中出现的顺序放置所有字段。 默认的 Rust 表示 repr(Rust) 消除了该限制，以及其他一些较小的限制，例如碰巧具有相同字段的类型的确定性字段排序。 也就是说，即使是共享所有相同字段、相同类型、相同顺序的两种不同类型，在使用默认 Rust 布局时，也不能保证布局相同！

由于我们现在可以对字段重新排序，因此我们可以按大小递减的顺序放置它们。 这意味着我们不再需要 Foo 字段之间的填充； 字段本身用于实现必要的对齐！ Foo 现在只是其字段的大小：只有 16 个字节。 这就是为什么 Rust 默认情况下不会对类型在内存中的布局方式提供很多保证的原因之一：通过给编译器更多的余地来重新排列事物，我们可以生成更高效的代码。

事实证明，还有第三种布局类型的方法，那就是告诉编译器我们不希望在字段之间有任何填充。 这样做，我们是说我们愿意承受使用未对齐访问带来的性能损失。 最常见的用例是当可以感受到每个额外内存字节的影响时，例如，如果您有很多该类型的实例，如果您的内存非常有限，或者如果您正在发送in- 通过网络连接等较低带宽介质进行内存表示。 要选择此行为，您可以使用 #[repr(packed)] 注释您的类型。 请记住，这可能会导致代码速度慢得多，并且在极端情况下，如果您尝试执行 CPU 仅支持对齐参数的操作，则可能会导致程序崩溃。

有时，您想要给特定字段或输入比技术要求更大的对齐方式。 您可以使用属性#[repr(align(n))] 来做到这一点。 一个常见的用例是确保连续存储在内存中（如数组）的不同值最终出现在 CPU 上的不同缓存行中。 这样，您就可以避免“错误共享”，这可能会导致并发程序的性能大幅下降。 当两个不同的 CPU 访问恰好共享缓存行的不同值时，就会发生错误共享； 虽然理论上它们可以并行操作，但它们最终都会竞争更新缓存中的同一个条目。 我们将在第 10 章中更详细地讨论并发性。

***复杂类型***

您可能对编译器如何在内存中表示其他 Rust 类型感到好奇。 这是一个快速参考：

**元组** 表示为一个结构体，其字段与元组值具有相同类型且顺序相同。

**数组** 表示为所包含类型的连续序列，元素之间没有填充。

**联合** 布局是为每个变体独立选择的。 对齐是所有变体中的最大对齐。

**枚举** 与 union 相同，但具有一个额外的隐藏共享字段，用于存储枚举变体判别式。 判别式是代码用来确定给定值包含哪些枚举变体的值。 判别域的大小取决于变体的数量。

***动态大小的类型和宽指针***

您可能在 Rust 文档的各个奇怪角落和错误消息中遇到过“Sized”标记特征。 通常，它出现是因为编译器希望您提供 Sized 类型，但您（显然）没有提供。 Rust 中的大多数类型都会自动实现 Sized，也就是说，它们具有在编译时已知的大小，但有两种常见类型则不然：特征对象和切片。 例如，如果您有 dyn Iterator 或 [u8]，那么它们没有明确定义的大小。 它们的大小取决于一些仅在程序运行时而不是在编译时已知的信息，这就是它们被称为“动态大小类型（DST）”的原因。 没有人提前知道您的函数接收到的 dyn Iterator 是这个 200 字节结构还是那个 8 字节结构。 这提出了一个问题：编译器通常必须知道某些内容的大小才能生成有效的代码，例如要为类型（i32，dyn Iterator，[u8]，i32）的元组分配多少空间或要使用什么偏移量 如果您的代码尝试访问第四个字段。 但如果类型不是 Sized，则该信息不可用。

编译器几乎在所有地方都要求调整类型的大小。 结构体字段、函数参数、返回值、变量类型和数组类型都必须调整大小。 这种限制非常常见，以至于您编写的每个类型绑定都包含 T: Sized，除非您使用 T: ?Sized 明确选择退出它（? 表示“可能不是”）。 但是，如果您有 DST 并想用它做一些事情，例如您确实希望您的函数接受特征对象或切片作为参数，那么这是非常没有帮助的。

弥合未调整大小和调整大小类型之间差距的方法是将未调整大小的类型放在*宽指针*（也称为*胖指针*）后面。 宽指针就像普通指针一样，但它包含一个额外的字大小字段，该字段提供有关该指针的附加信息，编译器需要这些信息来生成使用该指针的合理代码。 当您引用 DST 时，编译器会自动为您构造一个宽指针。 对于切片来说，额外的信息就是切片的长度。 对于特质对象——好吧，我们稍后会讨论这个问题。 至关重要的是，该宽指针*是*大小的。 具体来说，它的大小是 usize（目标平台上单词的大小）的两倍：一个 usize 用于保存指针，一个 usize 用于保存“完成”类型所需的额外信息。

*Box* *和* *Arc* *也支持存储宽指针，这就是为什么它们都支持* *T: ?Sized**.*



## Traits and Trait Bounds

Traits are a key piece of Rust’s type system—they are the glue that allows types to interoperate even though they don’t know about each other at the time they are defined. *The Rust Programming Language* does a great job of covering how to define and use traits, so I won’t go over that here. Instead, we’re going to take a look at some of the more technical aspects of traits: how they’re implemented, restrictions you have to adhere to, and some more esoteric uses of traits. 

### Compilation and Dispatch

By now, you’ve probably written a decent amount of generic code in Rust. You’ve used generic type parameters on types and methods, and maybe even a few trait bounds here and there. But have you ever wondered what actually happens to generic code when you compile it, or what happens when you call a trait method on a dyn Trait? 

When you write a type or function that is generic over T, you’re really telling the compiler to make a copy of that type or function for each type T. When you construct a Vec<i32> or a HashMap<String, bool>, the compiler essentially copy-pastes the generic type and all its implementation blocks and replaces all instances of each generic parameter with the concrete type you provided. It makes a full copy of the Vec type with every T replaced with i32, and a full copy of the HashMap type with every K replaced with String and every V with bool. 

*In reality, the compiler does not actually do a full copy-paste. It copies only parts of the code that you use, so if you never call* *find* *on a* *Vec**, the code for* *find* *won’t be copied and compiled.* 



The same thing applies to generic functions. Consider the code in Listing 2-2, which shows a generic method. 

```
impl String {
  pub fn contains(&self, p: impl Pattern) -> bool {
    p.is_contained_in(self)
  }
```

} 

*Listing 2-2: A generic method using static dispatch*

A copy of this method is made for every distinct pattern type (recall that impl Trait is shorthand for <T: Trait>). We need a different copy of the function body for each impl Pattern type because we need to know the address of the is_contained_in function to call it. The CPU needs to be told where to jump to and continue execution. For any *given* pattern, the com- piler knows that that address is the address of the place where that pattern type implements that trait method. But there is no one address we could use for *any* type, so we need to have one copy for each type, each with its own address to jump to. This is referred to as *static dispatch*, since for any given copy of the method, the address we are “dispatching to” is known statically. 

*You may have noticed that the word “static” is a little overloaded in this context.* Static *is generally used to refer to anything that is known at compile time, or can be treated as though it were, since it can then be written into static memory, as we dis- cussed in Chapter 1.* 

This process of going from a generic type to many non-generic types
 is called *monomorphization*, and it’s part of the reason generic Rust code usually performs just as well as non-generic code. By the time the com- piler starts optimizing your code, it’s as if no generics were there at all! Each instance is optimized separately and with all of the types known. As
 a result, the code is just as efficient as if the is_contained_in method of the pattern that is passed in were called directly without any traits present. The compiler has full knowledge of the types involved and can even inline the implementation of is_contained_in if it wishes. 

Monomorphization also comes at a cost: all those instantiations of your type need to be compiled separately, which can increase compile time if the compiler cannot optimize them away. Each monomorphized function also results in its own chunk of machine code, which can make your program larger. And because instructions aren’t shared between different instantia- tions of a generic type’s methods, the CPU’s instruction cache is also less effective as it now needs to hold multiple copies of effectively the same instructions. 



**NON-GENERIC INNER FUNCTIONS** 

Often, much of the code in a generic method is not type-dependent . Consider, for example, the implementation of HashMap::insert . The code to compute the hash of the supplied key depends on the key type of the map, but the code to walk the buckets of the map to find the insertion point may not . In cases like this, it would be more efficient to share the generated machine code for the non-generic parts of the method across monomorphizations, and only generate distinct copies where this is actually needed . 

One pattern you can use for cases like this is to declare a non-generic helper function inside the generic method that performs the shared operations . This leaves only the type-dependent code for the compiler to copy-paste for you while allowing the helper function to be shared . 

Making the function an inner function comes with the added benefit that you do not pollute your module with a single-purpose function . You can instead declare such a helper function outside the method instead; just be careful that you don’t make it a method under a generic impl block, as then it will still be monomorphized . 

The alternative to static dispatch is *dynamic dispatch*, which enables code to call a trait method on a generic type without knowing what that type is. I said earlier that the reason we needed multiple instances of the method in Listing 2-2 was that otherwise your program wouldn’t know what address to jump to in order to call the trait method is_contained_in on the given pattern. Well, with dynamic dispatch, the caller simply tells you. If you replace impl Pattern with &dyn Pattern, you tell the caller that they must give *two* pieces of information for this argument: the address of the pattern *and* the address of the is_contained_in method. In practice, the caller gives us a pointer to a chunk of memory called a virtual method table, or *vtable*, that holds the address of the implementation of *all* the trait’s methods for the type in question, one of which is is_contained_in. When the code inside the method wants to call a trait method on the provided pattern, it looks up the address of that pattern’s implementation of is_contained_in in the vtable and then calls the function at that address. This allows us to use the same function body regardless of what type the caller wants to use. 

*Every vtable also contains information about the concrete type’s layout and alignment since that information is always needed to work with a type. If you want an example of what an explicit vtable looks like, take a look at the* *std::task::RawWakerVTable* *type.* 

You’ll notice that when we opted in to dynamic dispatch using the dyn keyword, we had to place an & in front of it. The reason is that we no longer know at compile time the size of the pattern type that the caller passes in, so we don’t know how much space to set aside for it. In other words, dyn Trait is !Sized, where the ! means not. To make it Sized so we can take it as an argument, we place it behind a pointer (which we know the size of). Since we also need to pass along the table of method addresses, this pointer becomes a wide pointer, where the extra word holds the pointer to the vtable. You can use any type that is able to hold a wide pointer for dynamic dispatch, such as &mut, Box, and Arc. Listing 2-3 shows the dynamic dispatch equivalent of Listing 2-2. 

```
impl String {
  pub fn contains(&self, p: &dyn Pattern) -> bool {
    p.is_contained_in(&*self)
  }
```

} 

Listing 2-3: A generic method using dynamic dispatch 

The combination of a type that implements a trait and its vtable is known as a *trait object*. Most traits can be turned into trait objects, but not all. For example, the Clone trait, whose clone method returns Self, cannot be turned into a trait object. If we accept a dyn Clone trait object and then call clone on it, the compiler won’t know what type to return. Or, consider the Extend trait from the standard library, which has a method extend that is generic over the type of the provided iterator (so there may be many instances of it). If you were to call a method that took a dyn Extend, there would be no single address for extend to place in the trait object’s vtable; there would have to be one entry for every type extend might ever be called with. These are examples of traits that are not *object-safe* and therefore may not be turned into trait objects. To be object-safe, none of a trait’s methods can be generic or use the Self type. Furthermore, the trait cannot have any static methods (that is, methods whose first argument does not dereference to Self), since it would be impossible to know which instance of the method to call. It is not clear, for example, what code FromIterator::from_iter(&[0]) should execute. 

When reading about trait objects, you may see mentions of the trait bound Self: Sized. Such a bound implies that Self is not being used through a trait object (since it would then be !Sized). You can place that bound on a trait to require that the trait never use dynamic dispatch, or you can place it on a specific method to make that method unavailable when the trait is accessed through a trait object. Methods with a where Self: Sized bound are exempted when checking if a trait is object-safe. 

Dynamic dispatch cuts compile times, since it’s no longer necessary to compile multiple copies of types and methods, and it can improve the efficiency of your CPU instruction cache. However, it also prevents the com- piler from optimizing for the specific types that are used. With dynamic dispatch, all the compiler can do for find in Listing 2-2 is insert a call to the function through the vtable—it can no longer perform any additional optimizations as it does not know what code will sit on the other side of that function call. Furthermore, every method call on a trait object requires a lookup in the vtable, which adds a small amount of overhead over calling the method directly. 

When you’re given the choice between static and dynamic dispatch, there is rarely a clear-cut right answer. Broadly speaking, though, you’ll want to use static dispatch in your libraries and dynamic dispatch in your binaries. In a library, you want to allow your users to decide what kind of dispatch is best for them, since you don’t know what their needs are. If you use dynamic dispatch, they’re forced to do the same, whereas if you use static dispatch, they can choose whether to use dynamic dispatch or not. In a binary, on the other hand, you’re writing the final code, so there are no needs to consider except those of the code you are writing. Dynamic dis- patch often allows you to write cleaner code that leaves out generic param- eters and will compile more quickly, all at a (usually) marginal performance cost, so it’s usually the better choice for binaries. 

**Generic Traits** 

Rust traits can be generic in one of two ways: with generic type parameters like trait Foo<T> or with associated types like trait Foo { type Bar; }. The difference between these is not immediately apparent, but luckily the rule of thumb is quite simple: use an associated type if you expect only one implementation of the trait for a given type, and use a generic type parameter otherwise. 

The rationale for this is that associated types are often significantly easier to work with, but will not allow multiple implementations. So, more simply put, the advice is really just to use associated types whenever you can. 

With a generic trait, users must always specify all the generic parame- ters and repeat any bounds on those parameters. This can quickly get messy and hard to maintain. If you add a generic parameter to a trait, all users of that trait must also be updated to reflect the change. And since multiple implementations of a trait may exist for a given type, the compiler may have a hard time deciding which instance of the trait you meant to use, leading to awful disambiguating function calls like FromIterator::<u32>::from_iter. But the upside is that you can implement the trait multiple times for the same type—for example, you can implement PartialEq against mul- tiple right-hand side types for your type, or you can implement both FromIterator<T> *and* FromIterator<&T> where T: Clone, precisely because of the flexibility that generic traits provide. 

With associated types, on the other hand, the compiler needs to know only the type that implements the trait, and all the associated types follow (since there is only one implementation). This means the bounds can all live in the trait itself and do not need to be repeated on use. In turn, this allows the trait to add further associated types without affecting its users. And because the type dictates all the associated types of the trait, you never have to disambiguate with the unified function calling syntax shown in the previ- ous paragraph. However, you cannot implement Deref against multiple Target types, nor can you implement Iterator with multiple different Item types. 

**Coherence and the Orphan Rule** 

Rust has some fairly strict rules about where you can implement traits and what types you can implement them on. These rules exist to preserve the *coherence* property: for any given type and method, there is only ever one correct choice for which implementation of the method to use for that type. To see why this is important, consider what would happen if I could write my own implementation of the Display trait for the bool type from the standard library. Now, for any code that tries to print a bool value and includes my crate, the compiler won’t know whether to pick the implemen- tation I wrote or the one from the standard library. Neither choice is cor- rect or better than the other, and the compiler obviously cannot choose randomly. The same issue occurs if the standard library is not involved at all, but we instead have two crates that depend on each other, and they both implement a trait for some shared type. The coherence property ensures that the compiler never ends up in these situations and never has to make these choices: there will always be exactly one obvious choice. 

A facile way to uphold coherence would be to ensure only the crate that defines a trait can write implementations for that trait; if no one else can implement the trait, then there can be no conflicting implementa- tions elsewhere. However, this is too restrictive in practice and would essentially make traits useless, as there would be no way to implement traits like std::fmt::Debug and serde::Serialize for your own types, unless you got your own type included into the defining crate. The opposite extreme, saying that you can implement traits for only your own types, solves that problem but introduces another: a crate that defines a trait now cannot provide implementations of that trait for types in the stan- dard library or in other popular crates! Ideally, we would like to find some set of rules that balances the desire for downstream crates to implement upstream traits for their own types against the desire for upstream crates to be able to add implementations of their own traits without breaking downstream code. 

*Upstream refers to something your code depends on, and downstream refers to some- thing that depends on your code. Often, these terms are used in the direct sense of crate dependencies, but they can also be used to refer to authoritative forks of a codebase—if you do a fork of the Rust compiler, the official Rust compiler is your “upstream.”* 

In Rust, the rule that establishes that balance is the *orphan rule*. Simply stated, the orphan rule says that you can implement a trait for a type only if the trait *or* the type is local to your crate. So, you can implement Debug for your own type, and you can implement MyNeatTrait for bool, but you cannot implement Debug for bool. If you try, your code will not compile, and the compiler will tell you that there are conflicting implementations. 

This gets you pretty far; it allows you to implement your own traits for third-party types and to implement third-party traits for your own types. However, the orphan rule is not the end of the story. There are a number of additional implications, caveats, and exceptions to it that you should be aware of. 



**Blanket Implementations** 

The orphan rule allows you to implement traits over a range of types with code like impl<T> MyTrait for T where T: and so on. This is a *blanket implementation*—it is not limited to just one particular type but instead applies to a wide range of types. Only the crate that defines a trait is allowed to write a blanket imple- mentation, and adding a blanket implementation to an existing trait is consid- ered a breaking change. If it were not, a downstream crate that contained impl MyTrait for Foo could suddenly stop compiling just because you update the crate that defines MyTrait with an error about a conflicting implementation. 

**Fundamental Types** 

Some types are so essential that it’s necessary to allow anyone to implement traits on them, even if this seemingly violates the orphan rule. These types are marked with the #[fundamental] attribute and currently include &, &mut, and Box. For the purposes of the orphan rule, fundamental types may as well not exist—they are effectively erased before the orphan rule is checked in order to allow you to, for example, implement IntoIterator for &MyType. With just the orphan rule, this implementation would not be permitted since it implements a foreign trait for a foreign type—IntoIterator and & both come from the standard library. Adding a blanket implementation over a fundamental type is also considered a breaking change. 

**Covered Implementations** 

There are some limited cases where we want to allow implementing a for- eign trait for a foreign type, which the orphan rule does not normally allow. The simplest example of this is when you want to write something like impl From<MyType> for Vec<i32>. Here, the From trait is foreign, as is the Vec type,  yet there is no danger of violating coherence. This is because a conflicting implementation could be added only through a blanket implementation in the standard library (the standard library cannot otherwise name MyType), which is a breaking change anyway. 

To allow these kinds of implementations, the orphan rule includes a narrow exemption that permits implementing foreign traits for foreign types under a very specific set of circumstances. Specifically, a given impl<P1..=Pn> ForeignTrait<T1..=Tn> for T0 is allowed only if at least one Ti is a local type and no T before the first such Ti is one of the generic types P1..=Pn. Generic type parameters (Ps) *are* allowed to appear in T0..Ti as long as they are *covered* by some intermediate type. A T is covered if it appears as a type parameter to some other type (like Vec<T>), but not if it stands on its own (just T) or just appears behind a fundamental type like &T. So, all the implementations in Listing 2-4 are valid. 

```
impl<T> From<T> for MyType
impl<T> From<T> for MyType<T>
impl<T> From<MyType> for Vec<T>
impl<T> ForeignTrait<MyType, T> for Vec<T>
```

*Listing 2-4: Valid implementations of foreign traits for foreign types*



However, the implementations in Listing 2-5 are invalid. 

```
impl<T> ForeignTrait for T
impl<T> From<T> for T
impl<T> From<Vec<T>> for T
impl<T> From<MyType<T>> for T
impl<T> From<T> for Vec<T>
impl<T> ForeignTrait<T, MyType> for Vec<T>
```

*Listing 2-5: Invalid implementations of foreign traits for foreign types*

This relaxation of the orphan rule complicates the rules for what con- stitutes a breaking change when you add a new implementation for an exist- ing trait. In particular, adding a new implementation to an existing trait is non-breaking only if it contains at least one *new* local type, and that new local type satisfies the rules for the exemption described earlier. Adding any other new implementation is a breaking change. 

*Note that* *impl ForeignTrait for ForeignType* *is valid, but* *impl ForeignTrait for ForeignType* *is not! This may seem arbi- trary, but without this rule, you could write* *impl ForeignTrait  for ForeignType**, and another crate could write* *impl ForeignTrait for ForeignType**, and a conflict would arise only when the two crates were brought together. Instead of disallowing this pattern altogether, the orphan rule requires that your local type come before the type parameter, which breaks the tie and ensures that if both crates uphold coherence in isolation, they also uphold it when combined.* 

**Trait Bounds** 

The standard library is flush with trait bounds, whether it’s that the keys in a HashMap must implement Hash + Eq or that the function given to thread::spawn must be FnOnce + Send + 'static. When you write generic code yourself, it will almost certainly include trait bounds, as otherwise your code cannot do much with the type it is generic over. As you write more elaborate generic implementations, you’ll find that you also need more fidelity from your trait bounds, so let’s look at some of the ways to achieve that. 

First and foremost, trait bounds do not have to be of the form T: Trait where T is some type your implementation or type is generic over. The bounds can be arbitrary type restrictions and do not even need to include generic parameters, types of arguments, or local types. You can write a trait bound like where String: Clone, even though String: Clone is always true and contains no local types. You can also write where io::Error: From<MyError<T>>; your generic type parameters do not need to appear only on the left-hand side. This not only allows you to express more intricate bounds but also can save you from needlessly repeating bounds. For example, if your method wants to construct a HashMap<K, V, S> whose keys are some generic type T and whose value is a usize, instead of writing the bounds out like where T: Hash + Eq, S: BuildHasher + Default, you could write where HashMap<T, usize, S>: FromIterator. This saves you from looking up the exact bounds requirements for the methods you end up using and more clearly communicates the “true” requirement of your code. As you can see, it can also significantly reduce the complexity of your bounds if the bounds on the underlying trait methods you want to call are complex. 

**DERIVE TRAIT** 

While #[derive(Trait)] is extremely convenient, in the context of trait bounds, you should be aware of one subtlety around how it is often implemented . Many #[derive(Trait)] expansions desugar into impl Trait for Foo<T> where T: Trait . This is often what you want, but not always . For example, consider what happens if we try to derive Clone this way for Foo<T> and Foo contains an Arc<T> . Arc implements Clone regardless of whether T implements Clone, but due to the derived bounds, Foo will implement Clone only if T does! This isn’t usually too big of an issue, but it does add a bound where one isn’t needed . 

If we rename the type to Shared, the problem may become a little clearer . Imagine how confused a user that has a Shared<NotClone> will be when the compiler tells them that they cannot clone it! At the time of writing, this is how #[derive(Clone)] as provided by the standard library works, though this may change in the future . 

Sometimes, you want bounds on associated types of types you’re generic over. As an example, consider the iterator method flatten, which takes an iterator that produces items that in turn implement Iterator and produces an iterator of the items of those inner iterators. The type it pro- duces, Flatten, is generic over I, which is the type of the outer iterator. Flatten implements Iterator if I implements Iterator *and* the items yielded by I themselves implement IntoIterator. To enable you to write bounds like this, Rust lets you refer to associated types of a type using the syntax Type::AssocType. For example, we can refer to I’s Item type using I::Item. If a type has multiple associated types by the same name, such as if the trait that provides the associated type is itself generic (and therefore there are many implementations), you can disambiguate with the syntax <Type as Trait>::AssocType. Using this, you can write bounds not only for the outer iterator type but also for the item type of that outer iterator. 

In code that uses generics extensively, you may find that you need to write a bound that talks about references to a type. This is normally fine, as you’ll tend to also have a generic lifetime parameter that you can use as the lifetime for these references. In some cases, however, you want the bound to say “this reference implements this trait for any lifetime.” This type of bound is known as a *higher-ranked trait bound*, and it’s particularly useful in association with the Fn traits. For example, say you want to be generic over a function that takes a reference to a T and returns a reference to *inside* that T. If you write F: Fn(&T) -> &U, you need to provide a lifetime for those refer- ences, but you really want to say “any lifetime as long as the output is the same as the input.” Using a higher-ranked lifetime, you can write F: for<'a> Fn(&'a T) -> &'a U to say that for *any* lifetime 'a, the bound must hold. The Rust compiler is smart enough that it automatically adds the for when you write Fn bounds with references like this, which covers the majority of use cases for this feature. The explicit form is needed so exceedingly rarely that, at the time of writing, the standard library uses it in just three places—but it does happen and so is worth knowing about. 

To bring all of this together, consider the code in Listing 2-6, which can be used to implement Debug for any type that can be iterated over and whose elements are Debug. 

``` rust
impl Debug for AnyIterable
  where for<'a> &'a Self: IntoIterator,
        for<'a> <&'a Self as IntoIterator>::Item: Debug {
    fn fmt(&self, f: &mut Formatter) -> Result<(), Error> {
        f.debug_list().entries(self).finish()
}}
```

*Listing 2-6: An excessively generic implementation of *Debug* for any iterable collection*

You could copy-paste this implementation for pretty much any collec- tion type and it would “just work.” Of course, you may want a smarter debug implementation, but this illustrates the power of trait bounds quite well. 

**Marker Traits** 

Usually, we use traits to denote functionality that multiple types can sup- port; a Hash type can be hashed by calling hash, a Clone type can be cloned by calling clone, and a Debug type can be formatted for debugging by calling fmt. But not all traits are functional in this way. Some traits, called *marker traits*, instead indicate a property of the implementing type. Marker traits have no methods or associated types and serve just to tell you that a par- ticular type can or cannot be used in a certain way. For example, if a type implements the Send marker trait, it is safe to send across thread boundar- ies. If it does not implement this marker trait, it isn’t safe to send. There are no methods associated with this behavior; it’s just a fact about the type. The standard library has a number of these in the std::marker module, including Send, Sync, Copy, Sized, and Unpin. Most of these (all except Copy) are also *auto- traits*; the compiler automatically implements them for types unless the type contains something that does not implement the marker trait. 

Marker traits serve an important purpose in Rust: they allow you to write bounds that capture semantic requirements not directly expressed in the code. There is no call to send in code that requires that a type is Send. Instead, the code *assumes* that the given type is fine to use in a sepa- rate thread, and without marker traits the compiler would have no way of checking that assumption. It would be up to the programmer to remember the assumption and read the code very carefully, which we all know is not something we’d like to rely on. That path is riddled with data races, seg- faults, and other runtime issues. 

Similar to marker traits are *marker types*. These are unit types (like struct MyMarker;) that hold no data and have no methods. Marker types are useful for, well, marking a type as being in a particular state. They come in handy when you want to make it impossible for a user to misuse an API. For example, consider a type like SshConnection, which may or may not have been authenticated yet. You could add a generic type argument to SshConnection and then create two marker types: Unauthenticated and Authenticated. When the user first connects, they get SshConnection<Unauthe nticated>. In its impl block, you provide only a single method: connect. The connect method returns a SshConnection<Authenticated>, and it’s only in that impl block that you provide the remaining methods for running commands and such. We will look at this pattern further in Chapter 3. 

### Existential Types

In Rust you very rarely have to specify the types of variables you declare in the body of a function or the types of generic arguments to methods that you call. This is because of *type inference*, where the compiler decides what type to use based on what type the code the type appears in evaluates to. The compiler will usually infer types only for variables and for the argu- ments (and return types) of closures; top-level definitions like functions, types, traits, and trait implementation blocks all require that you explicitly name all types. There are a couple of reasons for this, but the primary one is that type inference is much easier when you have at least some known points to start the inference from. However, it’s not always easy, or even pos- sible, to fully name a type! For example, if you return a closure from a func- tion, or an async block from a trait method, its type does not have a name that you can type into your code. 

To handle situations like this, Rust supports *existential types*. Chances are, you have already seen existential types in action. All functions marked as async fn or with a return type of impl Trait have an existential return type: the signature does not give the true type of the return value, just a hint that the function returns *some* type that implements some set of traits that the caller can rely on. And crucially, the caller can only rely on the return type implementing those traits, and nothing else. 

*Technically, it isn’t strictly true that the caller relies on the return type and nothing else. The compiler will also propagate auto-traits like* *Send* *and* *Sync* *through* *impl Trait* *in return position. We’ll look at this more in the next chapter.* 

This behavior is what gives existential types their name: we are assert- ing that there exists some concrete type that matches the signature, and we leave it up to the compiler to find what that type is. The compiler will usu- ally then go figure that out by applying type inference on the body of the function. 

Not all instances of impl Trait use existential types. If you use impl Trait in argument position for a function, it’s really just shorthand for an unnamed generic parameter to that function. For example, fn foo(s: impl ToString) is mostly just syntax sugar for fn foo<S: ToString>(s: S). 

Existential types come in handy particularly when you implement traits that have associated types. For example, imagine you’re implementing the IntoIterator trait. It has an associated type IntoIter that holds the type of the iterator that the type in question can be turned into. With existential types, you do not need to define a separate iterator type to use for IntoIter. Instead, you can give the associated type as impl Iterator<Item = Self::Item> and just write an expression inside the fn into_iter(self) that evaluates to an Iterator, such as by using maps and filters over some existing iterator type. 

Existential types also provide a feature beyond mere convenience: they allow you to perform zero-cost type erasure. Instead of exporting helper types just because they appear in a public signature somewhere—iterators and futures are common examples of this—you can use existential types to hide the underlying concrete type. Users of your interface are shown only the traits that the relevant type implements, while the concrete type is left as an implementation detail. Not only does this simplify the interface, but it also enables you to change that implementation as you wish without break- ing downstream code in the future. 

### Summary

This chapter has provided a thorough review of the Rust type system. We’ve looked both at how the compiler manifests types in memory and how it rea- sons about the types themselves. This is important background material for writing unsafe code, complex application interfaces, and asynchronous code in later chapters. You’ll also find that much of the type reasoning from this chapter plays into how you design Rust code interfaces, which we’ll cover in the next chapter. 































