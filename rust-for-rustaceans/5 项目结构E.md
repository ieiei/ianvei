
本章提供了一些构建 Rust 项目的想法。 对于简单的项目，cargo new 设置的结构可能是你很少考虑的。 您可以添加一些模块来拆分代码，以及一些附加功能的依赖项，但仅此而已。 然而，随着项目规模和复杂性的增加，您会发现您需要超越这一点。 也许你的板条箱的编译时间已经失控，或者你需要条件依赖，或者你需要更好的持续集成策略。 在本章中，我们将了解 Rust 语言（特别是 Cargo）提供的一些工具，这些工具可以使管理此类事情变得更容易。

## Features

*Features*是 Rust 用于定制项目的主要工具。 从本质上讲，功能只是一个构建标志，板条箱可以将其传递给其依赖项以添加可选功能。 功能本身不具有语义意义，相反，*您*选择功能对*您的*板条箱意味着什么。

一般来说，我们以三种方式使用功能：启用可选依赖项、有条件地包含 crate 的附加组件以及增强代码的行为。 请注意，所有这些用途都是*附加的*； 特性可以添加到板条箱的功能中，但它们通常不应该执行诸如删除模块或替换类型或函数签名之类的操作。 这源于这样一个原则：如果开发人员对其 *Cargo.toml* 进行简单的更改，例如添加新的依赖项或启用某个功能，这不应该使他们的 crate 停止编译。 如果一个板条箱具有互斥的特性，那么该原则很快就会被抛在一边——如果板条箱 A 依赖于板条箱 C 的一个特性，而板条箱 B 依赖于 C 的另一个互斥特性，那么添加对板条箱 B 的依赖就会破坏板条箱 A！ 因此，我们通常遵循以下原则：如果板条箱 A 针对具有某些功能集的板条箱 C 进行编译，那么如果板条箱 C 上启用了所有功能，那么它也应该进行编译。

Cargo 非常遵循这一原则。 例如，如果两个板条箱（A 和 B）都依赖于板条箱 C，但它们各自在 C 上启用不同的功能，则 Cargo 将仅编译板条箱 C 一次，其中包含 A 或 B 所需的*所有*功能。 也就是说，它将跨 A 和 B 合并 C 所请求的功能。因此，通常很难向 Rust 包添加互斥的功能； 很可能有两个依赖项将依赖于具有不同功能的 crate，如果这些功能是相互排斥的，则下游 crate 将无法构建。

**N O T E** *我强烈建议您配置持续集成基础设施，以检查您的 crate 是否针对其功能的任意组合进行编译。 可以帮助您做到这一点的一个工具是* *cargo-hack**，您可以在* https://github.com/taiki-e/cargo-hack/ 找到它。

**Defining and Including Features** 

Features 在*Cargo.toml*中定义. 清单 5-1 显示了一个名为 foo 的 crate 示例，它具有启用可选依赖项 syn 的简单功能。

```toml
[package]
name = "foo"
...
[features]
derive = ["syn"]
[dependencies]
syn = { version = "1", optional = true }
```

*Listing 5-1: A feature that enables an optional dependency*

当 Cargo 编译这个 crate 时，它默认不会编译 syn crate，这会减少编译时间（通常会显着减少）。 仅当下游 crate 需要使用派生功能启用的 API 并明确选择加入时，才会编译 syn crate。 清单 5-2 显示了这样的下游 crate bar 如何启用导出功能，从而包含 syn 依赖项。

```toml
[package]
name = "bar"
...
[dependencies]
foo = { version = "1", features = ["derive"] }
```

*Listing 5-2: Enabling a feature of a dependency*

有些功能使用得非常频繁，因此让一个板条箱选择退出它们比加入它们更有意义。 为了支持这一点，Cargo 允许您为 crate 定义一组默认功能。 同样，它允许您选择退出依赖项的默认功能。 清单 5-3 显示了 foo 如何使其默认启用其派生功能，同时还选择退出 syn 的一些默认功能，而只启用派生功能所需的功能。

```
[package]
name = "foo"
...
[features]
derive = ["syn"]
default = ["derive"]
[dependencies.syn]
version = "1"
default-features = false
features = ["derive", "parsing", "printing"]
optional = true
```

*Listing 5-3: Adding and opting out of default features, and thus optional dependencies*

在这里，如果一个 crate 依赖于 foo 并且没有明确选择退出默认功能，它也会编译 foo 的 syn 依赖项。 反过来，syn 将仅使用列出的三个功能构建，而不使用其他功能。 通过这种方式选择退出默认功能，并仅选择您需要的功能，是减少编译时间的好方法！

> **OPTIONAL DEPENDENCIES AS FEATURES** 
> 
> 定义功能时，等号后面的列表本身就是功能列表。 乍一听，这可能有点奇怪——在清单 5-3 中， syn 是一个依赖项，而不是一个特性。 事实证明，Cargo 使每个可选依赖项都成为与依赖项同名的功能。 如果您尝试添加与可选依赖项同名的功能，您会看到这一点； 货物不允许。 Cargo 正在开发对功能和依赖项的不同命名空间的支持，但在撰写本文时尚未稳定。 同时，如果您想要以依赖项命名的功能，可以使用 package = "" 重命名依赖项以避免名称冲突。 功能启用的功能列表还可以包括依赖项的功能。 例如，您可以编写 derive = ["syn/derive"] 以使您的导出功能启用 syn 依赖项的导出功能。

**Using Features in Your Crate** 

使用功能时，您需要确保代码仅在可用时才使用依赖项。 如果您的功能启用了特定组件，您需要确保如果未启用该功能，则不包含该组件。

您可以使用“条件编译”来实现此目的，它允许您使用注释来给出应该或不应该编译特定代码段的条件。 条件编译主要使用#[cfg]属性来表示。 还有密切相关的cfg！ 宏，它允许您根据类似条件更改运行时行为。 您可以使用条件编译做各种巧妙的事情，正如我们将在本章后面看到的那样，但最基本的形式是 #[cfg(feature = "some-feature")]，这使得下一个“ 仅当启用某些功能时，才会编译源代码中的“thing”。 类似地， if cfg!(feature = "some-feature") 仅当启用派生功能时才相当于 if true （否则 if false）。

#[cfg] 属性比 cfg 更常用！ 宏，因为宏会根据功能修改运行时行为，这可能会导致难以确保功能是可加性的。 您可以将 #[cfg] 放在某些 Rust *项目* 的前面（例如函数和类型定义、impl 块、模块和 use 语句）以及某些其他结构（例如结构体字段、函数参数和语句）。 不过，#[cfg] 属性不能随处可见； Rust 语言团队会仔细限制它出现的位置，以免条件编译导致过于奇怪且难以调试的情况。

请记住，修改 API 的某些公共部分可能会无意中使某个功能变得不可添加，这反过来又可能使某些用户无法编译您的包。 您通常可以使用向后兼容更改的规则作为此处的经验法则 - 例如，如果您根据某个功能创建枚举变体或公共结构字段，则该类型也必须使用 #[non_exhaustive] 进行注释。 否则，如果由于依赖树中存在第二个 crate 而添加了该功能，则未启用该功能的依赖 crate 可能无法再编译。

**NOTE** *If you’re writing a large crate where you expect that your users will need only a subset of the functionality, you should consider making it so that larger components (usually modules) are guarded by features. That way, users can opt in to, and pay the compilation cost of, only the parts they really need.* 

### Workspaces

板条箱在 Rust 中扮演着许多角色——它们是依赖图中的顶点、特征一致性的边界以及编译功能的范围。 因此，每个 crate 都作为一个编译单元进行管理； Rust 编译器或多或少将一个 crate 视为一个大源文件，编译为一个块，最终转化为单个二进制输出（二进制文件或库）。

虽然这简化了编译器的许多方面，但这也意味着使用大的板条箱可能会很痛苦。 如果您更改应用程序一部分中的单元测试、注释或类型，编译器必须重新评估整个包以确定更改的内容（如果有）。 在内部，编译器实现了许多机制来加速这个过程，例如增量重新编译和并行代码生成，但最终，板条箱的大小是项目编译时间的一个重要因素。

因此，随着项目的增长，您可能希望将其拆分为多个内部相互依赖的 crate。 Cargo 正好具备您所需的便利功能：工作区。 *workspace* 是 crate 的集合（通常称为 *subcrates*），它们通过顶级 *Cargo.toml* 文件捆绑在一起，如清单 5-4 所示。

```rust
[workspace]
members = [
  "foo",
  "bar/one",
  "bar/two",
 ]
```

*Listing 5-4: A workspace Cargo .toml*

Members 数组是一个目录列表，每个目录在工作区中都包含一个 crate。 这些箱子在自己的子目录中都有自己的 *Cargo.toml* 文件，但它们共享一个 *Cargo.lock* 文件和一个输出目录。 板条箱名称不需要与成员中的条目匹配。 工作区中的 crate 共享一个名称前缀是常见的，但不是必需的，通常选择作为“主”crate 的名称。 例如，在 tokio crate 中，成员称为 tokio、tokio-test、tokio-macros 等。

也许工作区最重要的功能是您可以通过调用工作区根目录中的货物来与工作区的所有成员进行交互。 想检查它们是否全部编译？ 货物检查将全部检查。 想要运行所有测试吗？ 货物测试将测试所有这些。 它不像把所有东西都放在一个板条箱里那么方便，所以不要把所有东西都分成很小的板条箱，但这是一个非常好的近似值。

**N O T E** *Cargo commands will generally do the “right thing” in a workspace. If you ever need to disambiguate, such as if two workspace crates both have a binary by the same name, use the* *-p* *flag (for package). If you are in the subdirectory for a particular workspace crate, you can pass* *--workspace* *to perform the command for the entire workspace instead.* 

Once you have a workspace-level *Cargo.toml* with the array of workspace members, you can set your crates to depend on one another using path dependencies, as shown in Listing 5-5. 

Project Structure **71** 

```toml
# bar/two/Cargo.toml
[dependencies]
one = { path = "../one" }
# bar/one/Cargo.toml
[dependencies]
foo = { path = "../../foo" }
```

*Listing 5-5: Intercrate dependencies among workspace crates*

现在，如果您对 *bar/two* 中的板条箱进行更改，则只会重新编译该板条箱，因为 foo 和 *bar/one* 没有更改。 从头开始编译项目甚至可能会更快，因为编译器不需要评估整个项目源以获得优化机会。 

> **SPECIFYING INTRA-WORKSPACE DEPENDENCIES** 
> 
> The most obvious way to specify that one crate in a workspace depends on another is to use the path specifier, as shown in Listing 5-5 . However, if your individual subcrates are intended for public consumption, you may want to use version specifiers instead . 
> 
> Say you have a crate that depends on a Git version of the one crate from the bar workspace in Listing 5-5 with one = { git = ". . ." }, and a released version of foo (also from bar) with foo = "1.0.0" . Cargo will dutifully fetch the one Git repository, which holds the entire bar workspace, and see that one in turn depends on foo, located at ../../foo inside the workspace . But Cargo doesn’t know that the released version foo = "1.0.0" and the foo in the Git repository are the same crate! It considers them two separate dependencies that just happen to have the same name . 
> 
> You may already see where this is going . If you try to use any type from foo (1.0.0) with an API from one that accepts a type from foo, the compiler will reject the code . Even though the types have the same name, the compiler can’t know that they are the same underlying type . And the user will be thoroughly confused, since the compiler will say something like “expected foo::Type, got foo::Type .” 
> 
> The best way to mitigate this problem is to use path dependencies between subcrates only if they depend on unpublished changes . As long as one works with foo 1.0.0, it should list foo = "1.0.0" in its dependencies . Only if you make a change to foo that one needs should you change one to use a path dependency . And once you release a new version of foo that one can depend on, you should remove the path dependency again . 
> 
> This approach also has its shortcomings . Now if you change foo and then run the tests for one, you’ll see that one will be tested using the old foo, which may not be what you expected . You’ll probably want to configure your continuous integration infrastructure to test each subcrate both with the latest released versions of the other subcrates and with all of them configured to use path dependencies . 

### Project Configuration

Running cargo new sets you up with a minimal *Cargo.toml* that has the crate’s name, its version number, some author information, and an empty list of dependencies. That will take you pretty far, but as your project matures, there are a number of useful things you may want to add to your *Cargo.toml*. 

**Crate Metadata** 

The first and most obvious thing to add to your *Cargo.toml* is all the metadata directives that Cargo supports. In addition to obvious fields like description and homepage, it can be useful to include information such as the path to a *README* for the crate (readme), the default binary to run with cargo run (default-run), and additional keywords and categories to help *crates.io* categorize your crate. 

For crates with a more convoluted project layout, it’s also useful to set the include and exclude metadata fields. These dictate which files should be included and published in your package. By default, Cargo includes all files in a crate’s directory except any listed in your *.gitignore* file, but this may not be what you want if you also have large test fixtures, unrelated scripts, or other auxiliary data in the same directory that you *do* want under version control. As their names suggest, include and exclude allow you to include only a specific set of files or exclude files matching a given set of patterns, respectively. 

**N O T E** *If you have a crate that should never be published, or should be published only to certain alternative registries (that is, not to* crates.io*), you can set the* *publish* *directive to* *false* *or to a list of allowed registries.* 

The list of metadata directives you can use continues to grow, so make sure to periodically check in on the Manifest Format page of the Cargo reference (*https://doc.rust-lang.org/cargo/reference/manifest.html*). 

**Build Configuration** 

*Cargo.toml* can also give you control over how Cargo builds your crate. The most obvious tool for this is the build parameter, which allows you to write a completely custom build program for your crate (we’ll revisit this in Chapter 11). However, Cargo also provides two smaller, but very useful, mechanisms that we’ll explore here: patches and profiles. 

**[patch]** 

The [patch] section of *Cargo.toml* allows you to specify a different source for a dependency that you can use temporarily, no matter where in your dependencies the patched dependency appears. This is invaluable when you need to compile your crate against a modified version of some transitive dependency to test a bug fix, a performance improvement, or a new minor release you’re about to publish. Listing 5-6 shows an example of how you might temporarily use a variant of a set of dependencies. 

```rust
[patch.crates-io]
# use a local (presumably modified) source
regex = { path = "/home/jon/regex" }
# use a modification on a git branch
serde = { git = "https://github.com/serde-rs/serde.git", branch = "faster" }
# patch a git dependency
[patch.'https://github.com/jonhoo/project.git']
project = { path = "/home/jon/project" }
```

Listing 5-6: Overriding dependency sources in Cargo .toml using *[patch]*

Even if you patch a dependency, Cargo takes care to check the crate versions so that you don’t accidentally end up patching the wrong major version of a crate. If you for some reason transitively depend on multiple major versions of the same crate, you can patch each one by giving them distinct identifiers, as shown in Listing 5-7. 

```
[patch.crates-io]
nom4 = { path = "/home/jon/nom4", package = "nom" }
nom5 = { path = "/home/jon/nom5", package = "nom" }
```

Listing 5-7: Overriding multiple versions of the same crate in Cargo .toml using *[patch]* 

Cargo will look at the *Cargo.toml* inside each path, realize that /nom4 contains major version 4 and that /nom5 contains major version 5, and patch the two versions appropriately. The package keyword tells Cargo to look for a crate by the name nom in both cases instead of using the dependency identifiers (the part on the left) as it does by default. You can use package this way in your regular dependencies as well to rename a dependency! 

Keep in mind that patches are not taken into account in the package that’s uploaded when you publish a crate. A crate that depends on your crate will use only its own [patch] section (which may be empty), not that of your crate! 

> **CRATES VS. PACKAGES** 

> You may wonder what the difference between a package and a crate is. These two terms are often used interchangeably in informal contexts, but they also have specific definitions that vary depending on whether you’re talking about the Rust compiler, Cargo, crates.io, or something else . I personally think of a crate as a Rust module hierarchy starting at a root.rs file (one where you can use crate-level attributes like #![feature])—usually something like lib.rs or main.rs . In contrast, a package is a collection of crates and metadata, so essentially all that’s described by a Cargo.toml file . That may include a library crate, multiple binary crates, some integration test crates, and maybe even multiple workspace members that themselves have Cargo.toml files . 

**[profile]** 

The [profile] section lets you pass additional options to the Rust compiler in order to change the way it compiles your crate. These options fall primarily into three categories: performance options, debugging options, and options that change code behavior in user-defined ways. They all have different defaults depending on whether you are compiling in debug mode or in release mode (other modes also exist). 

The three primary performance options are opt-level, codegen-units, and lto. The opt-level option tweaks runtime performance by telling the compiler how aggressively to optimize your program (0 is “not at all,” 3 is “as much as you can”). The higher the setting, the more optimized your code will be, which *may* make it run faster. Extra optimization comes at the cost of higher compile times, though, which is why optimizations are generally enabled only for release builds. 

**NOTE** *You can also set* *opt-level* *to* *"s"* *to optimize for binary size, which may be important on embedded platforms.* 

The codegen-units option is about compile-time performance. It tells the compiler how many independent compilation tasks (*code generation units*) it is allowed to split the compilation of a single crate into. The more pieces a large crate’s compilation is split into, the faster it will compile, since more threads can help compile the crate in parallel. Unfortunately, to achieve this speedup, the threads need to work more or less independently, which means code optimization suffers. Imagine, for example, that the segment of a crate compiling in one thread could benefit from inlining some code in a different segment—since the two segments are independent, that inlining can’t happen! This setting, then, is a trade-off between compile-time performance and runtime performance. By default, Rust uses an effectively unbounded number of codegen units in debug mode (basically, “compile as fast as you can”) and a smaller number (16 at the time of writing) in release mode. 

The lto setting toggles *link-time optimization (LTO)*, which enables the compiler (or the linker, if you want to get technical about it) to jointly optimize bits of your program, known as *compilation units*, that were originally compiled separately. The exact details of LTO are beyond the scope of this book, but the basic idea is that the output from each compilation unit includes information about the code that went into that unit. After all the units have been compiled, the linker makes another pass over all of the units and uses that additional information to optimize the combined compiled code. This extra pass adds to the compile time but recovers most of the runtime performance that may have been lost due to splitting the compilation into smaller parts. In particular, LTO can offer significant performance boosts to performance-sensitive programs that might benefit from cross-crate optimization. Beware, though, that cross-crate LTO can add a lot to your compile time. 

Rust performs LTO across all the codegen units within each crate by default in an attempt to make up for the lost optimizations caused by using many codegen units. Since the LTO is performed only within each crate, rather than across crates, this extra pass isn’t too onerous, and the added compile time should be lower than the amount of time saved by using a lot of codegen units. Rust also offers a technique known as *thin LTO*, which allows the LTO pass to be mostly parallelized, at the cost of missing some optimizations a “full” LTO pass would have found. 

**NOTE** *LTO can be used to optimize across foreign function interface boundaries in many cases, too. See the* *linker-plugin-lto rustc* *flag for more details.* 

The [profile] section also supports flags that aid in debugging, such as debug, debug-assertions, and overflow-checks. The debug flag tells the compiler to include debug symbols in the compiled binary. This increases the binary size, but it means that you get function names and such, rather than just instruction addresses, in backtraces and profiles. The debug-assertions flag enables the debug_assert! macro and other related debug code that isn’t compiled otherwise (through cfg(debug_assertions)). Such code may make your program run slower, but it makes it easier to catch questionable behavior at runtime. The overflow-checks flag, as the name implies, enables overflow checks on integer operations. This slows them down (notice a trend here?) but can help you catch tricky bugs early on. By default, these are all enabled in debug mode and disabled in release mode. 

**[profile.\*.panic]** 

The [profile] section has another flag that deserves its own subsection: panic. This option dictates what happens when code in your program calls panic!, either directly or indirectly through something like unwrap. You can set panic to either unwind (the default on most platforms) or abort. We’ll talk more about panics and unwinding in Chapter 9, but I’ll give a quick summary here. 

Normally in Rust, when your program panics, the thread that panicked starts *unwinding* its stack. You can think of unwinding as forcibly returning recursively from the current function all the way to the bottom of that thread’s stack. That is, if main called foo, foo called bar, and bar called baz, a panic in baz would forcibly return from baz, then bar, then foo, and finally from main, resulting in the program exiting. A thread that unwinds will drop all values on the stack normally, which gives the values a chance to clean up resources, report errors, and so on. This gives the running system a chance to exit gracefully even in the case of a panic. 

When a thread panics and unwinds, other threads continue running unaffected. Only when (and if) the thread that ran main exits does the program terminate. That is, the panic is generally isolated to the thread in which the panic occurred. 

This means unwinding is a double-edged sword; the program is limping along with some failed components, which may cause all sorts of strange behaviors. For example, imagine a thread that panics halfway through updating the state in a Mutex. Any thread that subsequently acquires that Mutex must now be prepared to handle the fact that the state may be in a partially updated, inconsistent state. For this reason, some synchronization primitives (like Mutex) will remember if a panic occurred when they were last accessed and communicate that to any thread that tries to access the primitive subsequently. If a thread encounters such a state, it will normally also panic, which leads to a cascade that eventually terminates the entire program. But that is arguably better than continuing to run with corrupted state! 

The bookkeeping needed to support unwinding is not free, and it often requires special support by the compiler and the target platform. For example, many embedded platforms cannot unwind the stack efficiently at all. Rust therefore supports a different panic mode: abort ensures the whole program simply exits immediately when a panic occurs. In this mode, no threads get to do any cleanup. This may seem severe, and it is, but it ensures that the program is never running in a half-working state and that errors are made visible immediately. 

**WARNING** *The panic setting is global—if you set it to* *abort**, all your dependencies are also compiled with* *abort**.* 

You may have noticed that when a thread panics, it tends to print a *backtrace*: the trail of function calls that led to where the panic occurred. This is also a form of unwinding, though it is separate from the unwinding panic behavior discussed here. You can have backtraces even with panic=abort by passing -Cforce-unwind-tables to rustc, which makes rustc include the information necessary to walk back up the stack while still terminating the program on a panic. 

> **PROFILE OVERRIDES** 

> You can set profile options for just a particular dependency, or a particular profile, using profile overrides . For example, Listing 5-8 shows how to enable aggressive optimizations for the serde crate and moderate optimizations for all other crates in debug mode, using the [profile.**.package.**] syntax . ?

```toml
[profile.dev.package.serde]
opt-level = 3
[profile.dev.package."*"]
opt-level = 2
```

> *Listing 5-8: Overriding profile options for a specific dependency or for a specific mode*

> This kind of optimization override can be handy if some dependency would be prohibitively slow in debug mode (such as decompression or video encoding), and you need it optimized so that your test suite won’t take several days to complete . You can also specify global profile defaults using a [profile.dev] (or similar) section in the Cargo configuration file in ~/.cargo/config . 

> When you set optimization parameters for a specific dependency, keep in mind that the parameters apply only to the code compiled as part of that crate; if serde in this example has a generic method or type that you use in your crate,  the code of that method or type will be monomorphized and optimized in your crate, and your crate’s profile settings will apply, not those in the profile override for serde . 

### Conditional Compilation

Most Rust code you write is universal—it’ll work the same regardless of what CPU or operating system it runs on. But sometimes you’ll have to do something special to get the code to work on Windows, on ARM chips, or when compiled against a particular platform application binary interface (ABI). Or maybe you want to write an optimized version of a particular function when a given CPU instruction is available, or disable some slow but uninteresting setup code when running in a continuous integration (CI) environment. To cater to cases like these, Rust provides mechanisms for *conditional compilation*, in which a particular segment of code is compiled only if certain conditions are true of the compilation environment. 

We denote conditional compilation with the cfg keyword that you saw earlier in the chapter in “Using Features in Your Crate.” It usually appears in the form of the #[cfg(condition)] attribute, which says to compile the next item only if condition is true. Rust also has #[cfg_attr(condition, attribute)], which is compiled as #[attribute] if condition holds and is a no-op otherwise. You can also evaluate a cfg condition as a Boolean expression using the cfg!(condition) macro. 

Every cfg construct takes a single condition made up of options, like feature = "some-feature", and the combinators all, any, and not, which do what you would probably expect. Options are either simple names, like unix, or key/value pairs like those used by feature conditions. 

There are a number of interesting options you can make compilation dependent on. Let’s go through them, from most common to least common: 

**Feature options** 

You’ve already seen examples of these. Feature options take the form feature = "name-of-feature" and are considered true if the named feature is enabled. You can check for multiple features in a single condition using the combinators. For example, any(feature = "f1", feature = "f2") is true if either feature f1 or feature f2 is enabled. 

**Operating system options** 

These use key/value syntax with the key target_os and values like windows, macos, and linux. You can also specify a family of operating systems using target_family, which takes the value windows or unix. These are common enough that they have received their own named short forms, so you can use cfg(windows) and cfg(unix) directly. For example, if you wanted a particular code segment to be compiled only on macOS and Windows, you would write: #[cfg(any(windows, target_os = "macos"))]. 

**Context options** 

These let you tailor code to a particular compilation context. The most common of these is the test option, which is true only when the crate is being compiled under the test profile. Keep in mind that test is set only for the crate that is being tested, not for any of its dependencies. This also means that test is not set in your crate when running integration tests; it’s the integration tests that are compiled under the test profile, whereas your actual crate is compiled normally (that is, without test set). The same applies to the doc and doctest options, which are set only when building documentation or compiling doctests, respectively. There’s also the debug_assertions option, which is set in debug mode by default. 

**Tool options** 

Some tools, like clippy and Miri, set custom options (more on that later) that let you customize compilation when run under these tools. Usually, these options are named after the tool in question. For example, if you want a particular compute-intensive test not to run under Miri, you can give it the attribute #[cfg_attr(miri, ignore)]. 

**Architecture options** 

These let you compile based on the CPU instruction set the compiler is targeting. You can specify a particular architecture with target_arch, which takes values like x86, mips, and aarch64, or you can specify a particular platform feature with target_feature, which takes values like avx or sse2. For very low-level code, you may also find the target_endian and target_pointer_width options useful. 

**Compiler options** 

These let you adapt your code to the platform ABI it is compiled against and are available through target_env with values like gnu, msvc, and musl. For historical reasons, this value is often empty, especially on GNU platforms. You normally need this option only if you need to interface directly with the environment ABI, such as when linking against an ABI-specific symbol name using #[link]. 

While cfg conditions are usually used to customize code, some can also be used to customize dependencies. For example, the dependency winrt usually makes sense only on Windows, and the nix crate is probably useful only on Unix-based platforms. Listing 5-9 gives an example of how you can use cfg conditions for this: 

```toml
[target.'cfg(windows)'.dependencies]
winrt = "0.7"
[target.'cfg(unix)'.dependencies]
nix = "0.17"
```

*Listing 5-9: Conditional dependencies* 

Here, we specify that winrt version 0.7 should be considered a dependency only under cfg(windows) (so, on Windows), and nix version 0.17 only under cfg(unix) (so, on Linux, macOS, and other Unix-based platforms). One thing to keep in mind is that the [dependencies] section is evaluated very early in the build process, when only certain cfg options are available. In particular, feature and context options are not yet available at this point, so you cannot use this syntax to pull in dependencies based on features and contexts. You can, however, use any cfg that depends only on the target specification or architecture, as well as any options explicitly set by tools that call into rustc (like cfg(miri)). 

**NOTE** *While we’re on the topic of dependency specifications, I highly recommend that you set up your CI infrastructure to perform basic auditing of your dependencies using tools like* *cargo-deny* *and* *cargo-audit**. These tools will detect cases where you transitively depend on multiple major versions of a given dependency, where you depend on crates that are unmaintained or have known security vulnerabilities, or where you use licenses that you may want to avoid. Using such a tool is a great way to raise the quality of your codebase in an automated way!* 

It’s also quite simple to add your own custom conditional compilation options. You just have to make sure that --cfg=myoption is passed to rustc when rustc compiles your crate. The easiest way to do this is to add your --cfg to the RUSTFLAGS environment variable. This can come in handy in CI, where you may want to customize your test suite depending on whether it’s being run on CI or on a dev machine: add --cfg=ci to RUSTFLAGS in your CI setup, and then use cfg(ci) and cfg(not(ci)) in your code. Options set this way are also available in *Cargo.toml* dependencies. 

### Versioning

All Rust crates are versioned and are expected to follow Cargo’s implementation of semantic versioning. *Semantic versioning* dictates the rules for what kinds of changes require what kinds of version increases and for which versions are considered compatible, and in what ways. The RFC 1105 standard itself is well worth reading (it’s not horribly technical), but to summarize, it differentiates between three kinds of changes: breaking changes, which require a major version change; additions, which require a minor version change; and bug fixes, which require only a patch version change. RFC 1105 does a decent job of outlining what constitutes a breaking change in Rust, and we’ve touched on some aspects of it elsewhere in this book. 

I won’t go into detail here about the exact semantics of the different types of changes. Instead, I want to highlight some less straightforward ways version numbers come up in the Rust ecosystem, which you need to keep in mind when deciding how to version your own crates. 

**Minimum Supported Rust Version** 

第一个 Rust 主义是*最低支持的 Rust 版本 (MSRV)*。 Rust 社区对于项目在 MSRV 和版本控制方面应遵守哪些政策存在很多争论，并且没有真正好的答案。 问题的核心在于，一些 Rust 用户仅限于使用旧版本的 Rust，通常是在企业环境中，他们别无选择。 如果我们不断利用新稳定的 API，这些用户将无法编译我们的最新版本的板条箱，并将被抛在后面。

板条箱作者可以使用两种技术来让处于此位置的用户的生活变得更轻松。 第一个是建立 MSRV 策略，承诺新版本的板条箱将始终与过去 *X* 个月的任何稳定版本一起编译。 确切的数字各不相同，但 6 或 12 个月是常见的。 Rust 的六周发布周期分别对应于最新的四个或八个稳定版本。 引入项目的任何新代码都必须使用 MSRV 编译器进行编译（通常由 CI 检查），或者保留到 MSRV 策略允许按原样合并为止。 有时这可能会很痛苦，因为这意味着这些板条箱无法利用该语言提供的最新和最好的功能，但它会让您的用户的生活更轻松。

第二种技术是确保在 MSRV 发生更改时增加 crate 的次版本号。 因此，如果您发布了板条箱的 2.7.0 版本，并将 MSRV 从 Rust 1.44 增加到 Rust 1.45，那么停留在 1.44 且依赖于您的板条箱的项目可以使用依赖项版本说明符 version = "2, < 2.7”以保持项目正常运行，直到可以转移到 Rust 1.45。 重要的是要增加次要版本，而不仅仅是补丁版本，这样您仍然可以在必要时通过发布另一个补丁来为以前的 MSRV 版本发布关键的安全修复程序。

一些项目非常重视 MSRV 支持，以至于他们认为 MSRV 更改是重大更改，并增加了主版本号。 这意味着下游项目将明确必须选择加入 MSRV 更改，而不是选择退出，但这也意味着没有如此严格的 MSRV 要求的用户将不会在不更新其依赖项的情况下看到未来的错误修复，这可能需要 * 他们*也发布了重大变更。 正如我所说，这些解决方案都不是没有缺点的。

如今，在 Rust 生态系统中实施 MSRV 具有挑战性。 只有一小部分 crate 提供任何 MSRV 保证，即使您的依赖项提供了，您也需要不断监视它们以了解它们何时增加 MSRV。 当他们这样做时，您需要使用前面提到的受限版本边界来发布您的板条箱的新版本，以确保您的 MSRV 不会也发生变化。 这可能反过来迫使您放弃对依赖项进行的安全和性能更新，因为您必须继续使用旧版本，直到您的 MSRV 策略允许更新。 这个决定也会影响到你的家属。 有人提议在 Cargo 本身中建立 MSRV 检查，但截至撰写本文时，尚未稳定任何可行的方案。

**Minimal Dependency Versions** 

当您第一次添加依赖项时，并不总是清楚应该为该依赖项提供哪个版本说明符。 程序员通常选择最新版本，或者仅选择当前的主要版本，但这两种选择很可能都是错误的。 我所说的“错误”并不是说你的箱子无法编译，而是说做出这样的选择可能会给你的箱子的用户带来冲突。 让我们看看为什么这些案例都有问题。

首先，考虑添加对最新发布版本 Hugs = "1.7.3" 的依赖项的情况。 现在想象一下某个地方的开发人员依赖于你的板条箱，但他们也依赖于其他一些板条箱，foo，它本身依赖于拥抱。 进一步想象一下，foo 的作者非常谨慎地对待他们的 MSRV 政策，因此他们依赖于 Hugs =“1，<1.6”。 在这里，你会遇到麻烦。 当 Cargo 看到 Hugs = "1.7.3" 时，它只考虑 >=1.7 的版本。 但随后它发现 foo 对拥抱的依赖要求 <1.6，因此它放弃并报告没有与所有要求兼容的拥抱版本。

**NOTE** *实际上，有多种原因导致板条箱可能明确不需要较新版本的依赖项。 最常见的是强制执行 MSRV，以满足企业审核要求（较新的版本将包含未经审核的代码），并确保仅使用确切列出的版本的可重复构建。*

这是不幸的，因为你的箱子很可能可以很好地编译，比如说，拥抱 1.5.6。 也许它甚至可以与*任何* 1.X 版本一起编译！ 但是，通过使用最新版本号，您可以告诉 Cargo 仅考虑等于或高于该次要版本的版本。 那么解决方案是使用 Hugs = "1" 来代替吗？ 不，这也不完全正确。 可能您的代码确实依赖于仅在拥抱 1.6 中添加的内容，因此虽然 1.6.2 没问题，但 1.5.6 则不行。 如果您只在最终使用较新版本的情况下编译您的板条箱，您就不会注意到这一点，但如果依赖关系图中的某个板条箱指定了拥抱=“1，<1.5”，您的板条箱将无法编译！

正确的策略是列出包含您的 crate 所依赖的所有内容的最早版本，并确保即使您向 crate 添加新代码也是如此。 但是，除了搜索变更日志或通过反复试验之外，您如何确定这一点呢？ 最好的选择是使用 Cargo 的不稳定 -Zminimal-versions 标志，这使得您的板条箱对所有依赖项使用可接受的最低版本，而不是最大值。 然后，将所有依赖项设置为最新的主要版本号，尝试编译，并向任何不支持的依赖项添加次要版本。 冲洗并重复，直到一切编译正常，现在您已经达到了最低版本要求！

值得注意的是，与 MSRV 一样，最小版本检查面临着生态系统采用问题。 虽然您可能已正确设置所有版本说明符，但您所依赖的项目可能没有正确设置。 这使得 Cargo 最小版本标志很难在实践中使用（这也是它仍然不稳定的原因）。 如果您依赖 foo，并且 foo 依赖于 bar，且其说明符为 bar = "1"，而实际上它需要 bar = "1.4"，则无论您如何列出 foo，Cargo 都会报告它无法编译 foo，因为 -Z 标志 告诉它总是更喜欢最小版本。 您可以通过直接在“您的”依赖项中列出具有适当版本要求的 bar 来解决此问题，但这些解决方法的设置和维护可能会很痛苦。 您最终可能会列出大量依赖项，这些依赖项仅通过传递依赖项真正引入，并且随着时间的推移，您必须使该列表保持最新。

**NOTE** *当前的一个提议是提出一个标志，该标志支持当前包的最小版本，但支持依赖项的最大版本，这似乎很有希望。*

**Changelogs** 

对于除了最琐碎的板条箱之外的所有板条箱，我强烈建议保留更改日志。 没有什么比看到依赖项已收到主要版本更新，然后必须深入挖掘 Git 日志以找出更改的内容以及如何更新代码更令人沮丧的了。 我建议您不要将 Git 日志转储到名为 *changelog* 的文件中，而应保留手动更改日志。 它更有可能有用。

A simple but good format for changelogs is the Keep a Changelog format documented at *https://keepachangelog.com/*. 

**Unreleased Versions** 

即使依赖项的来源是目录或 Git 存储库，Rust 也会考虑版本号。 这意味着即使您尚未向 *crates.io* 发布版本，语义版本控制也很重要； 版本之间的 *Cargo.toml* 中列出的版本很重要。 语义版本控制标准并没有规定如何处理这种情况，但我将提供一个工作正常且不会太繁重的工作流程。

发布版本后，立即将 *Cargo.toml* 中的版本号更新为下一个补丁版本，后缀如 *-alpha.1*。 如果您刚刚发布了 2.0.3，请将新版本设为 2.0.4-alpha.1。 如果您刚刚发布了 alpha，请增加 alpha 数字。

当您在版本之间更改代码时，请留意附加或破坏性更改。 如果发生这种情况，并且自上次发布以来相应的版本号没有更改，则增加它。 例如，如果最后发布的版本是 2.0.3，当前版本是 2.0.4-alpha.2，并且您进行附加更改，则将包含更改的版本设为 2.1.0-alpha.1。 如果您进行了重大更改，它将变为 3.0.0-alpha.1。 如果已经进行了相应的版本增加，则只需增加 alpha 数字即可。

当您发布版本时，删除后缀（除非您想要进行预发布），然后发布，并从顶部开始。

这个过程很有效，因为它使两个常见的工作流程工作得更好。 首先，假设开发人员依赖于您的 crate 的主要版本 2，但他们需要目前仅在 Git 中可用的功能。 然后你提交一个重大变更。 如果您不同时增加主要版本，他们的代码会突然以意想不到的方式失败，要么无法编译，要么由于奇怪的运行时问题。 如果您按照此处列出的程序进行操作，Cargo 会通知他们发生了重大更改，并且他们必须解决该问题或固定特定提交。

接下来，假设开发人员需要一个他们刚刚为您的板条箱贡献的功能，但该功能尚未包含在您的板条箱的任何已发布版本中。 他们已经在 Git 依赖项后面使用您的 crate 一段时间了，因此他们项目中的其他开发人员已经对您的 crate 存储库进行了较旧的签出。 如果您不增加 Git 中的主版本号，则该开发人员无法告知他们的项目现在依赖于刚刚合并的功能。 如果他们推动更改，他们的开发人员同事会发现该项目不再编译，因为 Cargo 将重用旧的结账。 另一方面，如果开发人员可以增加 Git 依赖项的次版本号，那么 Cargo 将意识到旧的签出已过时。

这个工作流程绝不是完美的。 它没有提供一种在版本之间传达多个较小或主要更改的好方法，并且您仍然需要做一些工作来跟踪版本。 然而，它确实解决了 Rust 开发人员在处理 Git 依赖项时遇到的两个最常见问题，即使您在版本之间进行了多次此类更改，此工作流程仍然会捕获许多问题。

如果您不太担心版本中的小版本号或连续版本号，您可以通过简单地始终增加版本号的适当部分来改进此建议的工作流程。 但请注意，根据您进行此类更改的频率，这可能会使您的版本号变得相当大！

## Summary

在本章中，我们研究了许多用于配置、组织和发布 crate 的机制，这既是为了您自己也是为了他人的利益。 我们还讨论了使用 Cargo 中的依赖项和功能时的一些常见问题，希望这些问题将来不会让您陷入困境。 在下一章中，我们将转向测试并深入探讨如何超越我们所了解和喜爱的 Rust 简单的 #[test] 函数。