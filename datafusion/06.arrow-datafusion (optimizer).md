datafusion的优化器包括逻辑优化和物理优化两个过程。逻辑优化是基于规则的优化(RBO)，对输入的逻辑执行计划按顺序应用一些优化规则，从而使整个逻辑执行计划变得更好。物理优化是基于代价的优化(CBO)，为上一阶段产生的逻辑执行计划制定物理执行计划。
``` rust
dataframe.into_optimized_plan();
SessionState::create_logical_plan();
dataframe.create_physical_plan();
SessionState::create_physical_plan();
```
dataframe 经过逻辑优化后，创建生成物理计划，然后再对物理计划进行物理优化后，最后转化为执行计划。

## 逻辑优化
``` rust
Optimizer::optimize<F>(&self, 
	plan: &LogicalPlan, 
	config: &dyn OptimizerConfig,
    mut observer: F) -> Result<LogicalPlan>
```
### 优化器规则 OptimizerRule:
``` rust
pub trait OptimizerRule {
    fn try_optimize(&self, plan: &LogicalPlan, config: &dyn OptimizerConfig) -> Result<Option<LogicalPlan>>;
    fn name(&self) -> &str;
    fn apply_order(&self) -> Option<ApplyOrder> { None }
}
```

### 优化顺序 ApplyOrder：
不同的优化器优化的递归顺序可能会有所不同，datafusion定义了两种优化顺序
- TopDown
	自顶向下, 先optimize node  再optimize inputs
- BottomUp
	自底向上, 先optimize inputs 再optimize node

### 表达式重写
逻辑优化过程需要依赖对表达式进行重写。

ExprRewriter接口声明：
```
pub trait ExprRewriter<E: ExprRewritable = Expr>: Sized {
    /// Invoked before any children of `expr` are rewritten /
    /// visited. Default implementation returns `Ok(RewriteRecursion::Continue)`
    fn pre_visit(&mut self, _expr: &E) -> Result<RewriteRecursion> {
        Ok(RewriteRecursion::Continue)
    }

    /// Invoked after all children of `expr` have been mutated and
    /// returns a potentially modified expr.
    fn mutate(&mut self, expr: E) -> Result<E>;
}
```
RewriteRecursion类型：
- Continue      继续递归重写
- Mutate          调用ExpeRewriter::mutate 并结束返回
- Stop              结束递归重写
- Skip               跳过本次重写并且继续递归


### 具体实现 Impl：
- InlineTableScan                              # 优化表扫描和内联
- TypeCoercion                                 # 类型重写
- SimplifyExpressions                      # 简化表达式
- UnwrapCastInComparison            # 去掉cast 重写表达式
- ReplaceDistinctWithAggregate    # 把 Distinct 替换成 Aggregate
- DecorrelateWhereExists                # 重写子查询到join
- DecorrelateWhereIn                       # 子查询中where in 操作
- ScalarSubqueryToJoin                   # 标量子查询
- ExtractEquijoinPredicate               # 提炼equi-join
- SimplifyExpressions                       # 简化子表达式
- MergeProjection                              # merge语句优化
- RewriteDisjunctivePredicate          # 提取谓语重写，扁平化表达式
- EliminateDuplicatedExpr                # 排除重复的表达式
- EliminateFilter                                  # 排除Filter
- EliminateCrossJoin                          # 排除CrossJoin
- CommonSubexprEliminate             # Perform Common Sub-expression Elimination optimization. 
- EliminateLimit                                   # Optimization rule that bottom-up to eliminate plan by propagating empty_relation.
- PropagateEmptyRelation                # Optimization rule that bottom-up to eliminate plan by propagating empty_relation.
- FilterNullJoinKeys                            # FilterNullJoinKeys
- EliminateOuterJoin                          # Attempt to replace outer joins with inner joins.
- PushDownLimit                                # LIMIT下推
- PushDownFilter                                # Filter下推
- SingleDistinctToGroupBy                # single distinct to group by optimizer rule
- SimplifyExpressions                         # previous optimizations added expressions and projections simplify
- UnwrapCastInComparison               # attempts to remove casts from comparisons to literals
- CommonSubexprEliminate              # Perform Common Sub-expression Elimination optimization.
- PushDownProjection                        # Optimizer that removes unused projections and aggregations from plans
- EliminateProjection                           # Optimization rule that eliminate unnecessary
- PushDownLimit                                 # Optimization rule that tries to push down LIMIT





## 物理优化


### 优化器规则 PhysicalOptimizerRule:
``` rust
pub trait PhysicalOptimizerRule {
    fn optimize(
        &self,
        plan: Arc<dyn ExecutionPlan>,
        config: &ConfigOptions,
    ) -> Result<Arc<dyn ExecutionPlan>>;
    fn name(&self) -> &str;
    fn schema_check(&self) -> bool;
}
```


### 实现Impl:
#### AggregateStatistics
	Utilizing exact statistics from sources to avoid scanning data(利用来源的精确统计数据来避免扫描数据)

```rust 
optimize(&self, plan: Arc<dyn ExecutionPlan>, config: &ConfigOptions) -> Result<Arc<dyn ExecutionPlan>>
	take_optimizable(node: &dyn ExecutionPlan) -> Option<Arc<dyn ExecutionPlan>>
	take_optimizable_column_count(agg_expr: &dyn AggregateExpr, stats: &Statistics) -> Option<(ScalarValue, String)>
	take_optimizable_max(agg_expr: &dyn AggregateExpr, stats: &Statistics) -> Option<(ScalarValue, String)>
	take_optimizable_min(agg_expr: &dyn AggregateExpr, stats: &Statistics) -> Option<(ScalarValue, String)>
	take_optimizable_table_count(agg_expr: &dyn AggregateExpr, stats: &Statistics) -> Option<(ScalarValue, &'static str)>
```

#### Repartition 
	Repartition optimizer that introduces repartition nodes to increase the level of parallelism available
	目标是通过进行重新分区增加分区数量以提高可用的并行度

```rust
optimize(&self, plan: Arc<dyn ExecutionPlan>, config: &ConfigOptions) -> Result<Arc<dyn ExecutionPlan>>
	plan_has_required_input_ordering(plan: &dyn ExecutionPlan) -> bool
	optimize_partitions(target_partitions: usize, plan: Arc<dyn ExecutionPlan>, is_root: bool, can_reorder: bool, would_benefit: bool, repartition_file_scans: bool, repartition_file_min_size: usize) -> Result<Arc<dyn ExecutionPlan>>
```

#### GlobalSortSelection
	Currently for a sort operator, if
	- there are more than one input partitions
	- and there's some limit which can be pushed down to each of its input partitions
	then [SortPreservingMergeExec] with local sort with a limit pushed down will be preferred;
	Otherwise, the normal global sort [SortExec] will be used.
	Later more intelligent statistics-based decision can also be introduced.
	For example, for a small data set, the global sort may be efficient enough

``` rust
optimize(&self, plan: Arc<dyn ExecutionPlan>, config: &ConfigOptions) -> Result<Arc<dyn ExecutionPlan>>
```

#### JoinSelection
	For hash join with the partition mode [PartitionMode::Auto], JoinSelection rule will make
	a cost based decision to select which PartitionMode mode(Partitioned/CollectLeft) is optimal
	based on the available statistics that the inputs have.
	If the statistics information is not available, the partition mode will fall back to [PartitionMode::Partitioned].
	
	JoinSelection rule will also reorder the build and probe phase of the hash joins
	based on the avaliable statistics that the inputs have.
	The rule optimizes the order such that the left (build) side of the join is the smallest.
	If the statistics information is not available, the order stays the same as the original query.
	JoinSelection rule will also swap the left and right sides for cross join to keep the left side
	is the smallest.

``` rust
optimize(&self, plan: Arc<dyn ExecutionPlan>, config: &ConfigOptions) -> Result<Arc<dyn ExecutionPlan>>
	partitioned_hash_join(hash_join: &HashJoinExec) -> Result<Arc<dyn ExecutionPlan>>
	should_swap_join_order(left: &dyn ExecutionPlan, right: &dyn ExecutionPlan) -> bool
	swap_hash_join( hash_join: &HashJoinExec, partition_mode: PartitionMode, ) -> Result<Arc<dyn ExecutionPlan>>
		swap_join_filter(filter: Option<&JoinFilter>) -> Option<JoinFilter>
		swap_join_type(join_type: JoinType) -> JoinType
	swap_reverting_projection( left_schema: &Schema, right_schema: &Schema, ) -> Vec<(Arc<dyn PhysicalExpr>, String)>
	try_collect_left( hash_join: &HashJoinExec, collect_threshold: Option<usize>, ) -> Result<Option<Arc<dyn ExecutionPlan>>>
		supports_collect_by_size( plan: &dyn ExecutionPlan, collection_size_threshold: usize, ) -> bool
		supports_swap(join_type: JoinType) -> bool
```

#### EnforceDistribution
	The EnforceDistribution rule ensures that distribution requirements are met
	in the strictest way. It might add additional [RepartitionExec] to the plan tree
	and give a non-optimal plan, but it can avoid the possible data skew in joins.
	
	For example for a HashJoin with keys(a, b, c), the required Distribution(a, b, c) can be satisfied by
	several alternative partitioning ways: [(a, b, c), (a, b), (a, c), (b, c), (a), (b), (c), ( )].
	
	This rule only chooses the exactly match and satisfies the Distribution(a, b, c) by a HashPartition(a, b, c).

``` rust
optimize(&self, plan: Arc<dyn ExecutionPlan>, config: &ConfigOptions) -> Result<Arc<dyn ExecutionPlan>>
	adjust_input_keys_ordering(requirements: PlanWithKeyRequirements) -> Result<Option<PlanWithKeyRequirements>>
	ensure_distribution(plan: Arc<dyn crate::physical_plan::ExecutionPlan>, target_partitions: usize) -> Result<Arc<dyn crate::physical_plan::ExecutionPlan>>
	expected_expr_positions(current: &[Arc<dyn PhysicalExpr>], expected: &[Arc<dyn PhysicalExpr>]) -> Option<Vec<usize>>
	extract_join_keys(on: &[(Column, Column)]) -> JoinKeyPairs
	map_columns_before_projection(parent_required: &[Arc<dyn PhysicalExpr>], proj_exprs: &[(Arc<dyn PhysicalExpr>, String)]) -> Vec<Arc<dyn PhysicalExpr>>
	new_join_conditions(new_left_keys: &[Arc<dyn PhysicalExpr>], new_right_keys: &[Arc<dyn PhysicalExpr>]) -> Vec<(Column, Column)>
	reorder_aggregate_keys(agg_plan: Arc<dyn ExecutionPlan>, parent_required: &[Arc<dyn PhysicalExpr>], group_by: &PhysicalGroupBy, aggr_expr: &[Arc<dyn AggregateExpr>], agg_input: Arc<dyn ExecutionPlan>, input_schema: &SchemaRef) -> Result<PlanWithKeyRequirements>
	reorder_current_join_keys(join_keys: JoinKeyPairs, left_partition: Option<Partitioning>, right_partition: Option<Partitioning>, left_equivalence_properties: &EquivalenceProperties, right_equivalence_properties: &EquivalenceProperties) -> Option<(JoinKeyPairs, Vec<usize>)>
	reorder_join_keys_to_inputs(plan: Arc<dyn crate::physical_plan::ExecutionPlan>) -> Result<Arc<dyn crate::physical_plan::ExecutionPlan>>
	reorder_partitioned_join_keys<F>(join_plan: Arc<dyn ExecutionPlan>, parent_required: &[Arc<dyn PhysicalExpr>], on: &[(Column, Column)], sort_options: Vec<SortOptions>, join_constructor: &F) -> Result<PlanWithKeyRequirements> where F: Fn((Vec<(Column, Column)>, Vec<SortOptions>)) -> Result<Arc<dyn ExecutionPlan>>
	shift_right_required(parent_required: &[Arc<dyn PhysicalExpr>], left_columns_len: usize) -> Option<Vec<Arc<dyn PhysicalExpr>>>
```

#### EnforceSorting
    EnforceSorting optimizer rule inspects the physical plan with respect
    to local sorting requirements and does the following:
    - Adds a [SortExec] when a requirement is not met,
    - Removes an already-existing [SortExec] if it is possible to prove
      that this sort is unnecessary
    The rule can work on valid *and* invalid physical plans with respect to
    sorting requirements, but always produces a valid physical plan in this sense.
    
    A non-realistic but easy to follow example for sort removals: Assume that we
    somehow get the fragment
    
    ```text
    SortExec: expr=[nullable_col@0 ASC]
      SortExec: expr=[non_nullable_col@1 ASC]
    ```
    
    in the physical plan. The first sort is unnecessary since its result is overwritten
    by another SortExec. Therefore, this rule removes it from the physical plan.

``` rust
optimize(&self, plan: Arc<dyn ExecutionPlan>, config: &ConfigOptions) -> Result<Arc<dyn ExecutionPlan>>
	plan_requirements.transform_up(&ensure_sorting)
	plan_with_coalesce_partitions.transform_up(&parallelize_sorts)
```
#### PipelineFixer
    The [PipelineFixer] rule tries to modify a given plan so that it can
    accommodate its infinite sources, if there are any. If this is not
    possible, the rule emits a diagnostic error message.

```rust
optimize(&self, plan: Arc<dyn ExecutionPlan>, config: &ConfigOptions) -> Result<Arc<dyn ExecutionPlan>>
	hash_join_convert_symmetric_subrule( input: PipelineStatePropagator, ) -> Option<Result<PipelineStatePropagator>>
		is_suitable_for_symmetric_hash_join(hash_join: &HashJoinExec) -> Result<bool>
			check_support(expr: &Arc<dyn PhysicalExpr>) -> bool
	hash_join_swap_subrule( input: PipelineStatePropagator, ) -> Option<Result<PipelineStatePropagator>>
		swap(hash_join: &HashJoinExec) -> Result<Arc<dyn ExecutionPlan>>
	apply_subrules_and_check_finiteness_requirements( mut input: PipelineStatePropagator, physical_optimizer_subrules: &Vec<Box<PipelineFixerSubrule>>, ) -> Result<Option<PipelineStatePropagator>>
		
```
#### CoalesceBatches
    CoalesceBatches optimizer that groups batches together rows
    in bigger batches to avoid overhead with small batches

``` rust
optimize(&self, plan: Arc<dyn crate::physical_plan::ExecutionPlan>, config: &ConfigOptions) -> Result<Arc<dyn crate::physical_plan::ExecutionPlan>>
```
#### PipelineChecker
    The [PipelineChecker] rule ensures that a given plan can accommodate its
    infinite sources, if there are any. It will reject non-runnable query plans
    that use pipeline-breaking operators on infinite input(s).

```rust
optimize( &self, plan: Arc<dyn ExecutionPlan>, _config: &ConfigOptions, ) -> Result<Arc<dyn ExecutionPlan>>
	pipeline.transform_up(&check_finiteness_requirements);
