datafusion跟物理存储（物理文件）的交互，datafusion将底层都抽象到datasource上。


## 表视角
物理存储最后都要以表的形式呈现给上游

### TableProvider 表定义
``` rust
pub trait TableProvider: Sync + Send {
    fn schema(&self) -> SchemaRef;
    fn table_type(&self) -> TableType;
    fn get_table_definition(&self) -> Option<&str> { None }
    fn get_logical_plan(&self) -> Option<&LogicalPlan> { None }
    async fn scan(
        &self,
        state: &SessionState,
        projection: Option<&Vec<usize>>,
        filters: &[Expr],
        // limit can be used to reduce the amount scanned
        // from the datasource as a performance optimization.
        // If set, it contains the amount of rows needed by the `LogicalPlan`,
        // The datasource should return *at least* this number of rows if available.
        limit: Option<usize>,
    ) -> Result<Arc<dyn ExecutionPlan>>;

    #[deprecated(since = "20.0.0", note = "use supports_filters_pushdown instead")]
    fn supports_filter_pushdown(
        &self,
        _filter: &Expr,
    ) -> Result<TableProviderFilterPushDown> {
        Ok(TableProviderFilterPushDown::Unsupported)
    }

    #[allow(deprecated)]
    fn supports_filters_pushdown(
        &self,
        filters: &[&Expr],
    ) -> Result<Vec<TableProviderFilterPushDown>> {
        filters
            .iter()
            .map(|f| self.supports_filter_pushdown(f))
            .collect()
    }

    /// Get statistics for this table, if available
    fn statistics(&self) -> Option<Statistics> {
        None
    }

    /// Insert into this table
    async fn insert_into(
        &self,
        _state: &SessionState,
        _input: &LogicalPlan,
    ) -> Result<()> {
        let msg = "Insertion not implemented for this table".to_owned();
        Err(DataFusionError::NotImplemented(msg))
    }
}

```

具体实现：
- ListingTable (文件系统物理存储表)
- MemTable    (内存表)
- ViewTable    (视图表)
- StreamingTable  (流数据表)
- DataFrameTableProvider  (提供给dataframe的api用)
- EmptyTable  (空表，用于测试开发和调执行计划用)

#### TableType 表类型
- Base  (An ordinary physical table)
- View  (A non-materialised table that itself uses a query internally to provide data)
- Temporary  (A transient table)

## 文件视角
### FileFormat 文件格式定义
``` rust
pub trait FileFormat: Send + Sync + fmt::Debug {
    /// Infer the common schema of the provided objects. The objects will usually
    /// be analysed up to a given number of records or files (as specified in the
    /// format config) then give the estimated common schema. This might fail if
    /// the files have schemas that cannot be merged.
    async fn infer_schema(
        &self,
        state: &SessionState,
        store: &Arc<dyn ObjectStore>,
        objects: &[ObjectMeta],
    ) -> Result<SchemaRef>;

    /// Infer the statistics for the provided object. The cost and accuracy of the
    /// estimated statistics might vary greatly between file formats.
    ///
    /// `table_schema` is the (combined) schema of the overall table
    /// and may be a superset of the schema contained in this file.
    ///
    /// TODO: should the file source return statistics for only columns referred to in the table schema?
    async fn infer_stats(
        &self,
        state: &SessionState,
        store: &Arc<dyn ObjectStore>,
        table_schema: SchemaRef,
        object: &ObjectMeta,
    ) -> Result<Statistics>;

    /// Take a list of files and convert it to the appropriate executor
    /// according to this file format.
    async fn create_physical_plan(
        &self,
        state: &SessionState,
        conf: FileScanConfig,
        filters: Option<&Arc<dyn PhysicalExpr>>,
    ) -> Result<Arc<dyn ExecutionPlan>>;
}
```


## 变文件转化：
![[fileformat.png]]




read_table过程是先根据文件推到出schema， 同时生成TableScan执行计划作为开是执行计划，构建成dataframe
``` rust

read_(csv/avro/parquet/json) -> \_read_type() -> get_resolved_schema() -> read_table() -> LogicalPlan::TableScan
	provided_schemas = provided_schemas || FileFormat::infer_schema()
		ParquetFormat::fetch_schema()
		avro_to_arrow::read_avro_schema_from_reader()
		JsonFormat::infer_json_schema_from_iterator()
		CsvFormat::infer_schema_from_stream()
	provider = ListingTable::try_new(config)
	LogicalPlanBuilder::scan(UNNAMED_TABLE, provider_as_source(provider), None)
```

``` rust
register_(csv/avro/parquet/json) -> register_listing_table() -> register_table() -> TableProvider[trait]
sql() -> register_table()
	provided_schemas = provided_schemas || FileFormat::infer_schema()
		ParquetFormat::fetch_schema()
		avro_to_arrow::read_avro_schema_from_reader()
		JsonFormat::infer_json_schema_from_iterator()
		CsvFormat::infer_schema_from_stream()
```
``` rust
sql()
	create_logical_plan()
	LogicalPlan::CreateMemoryTable()
		register_table()
		return_empty_dataframe()
```